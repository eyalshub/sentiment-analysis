{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FmPUYlPSblt",
        "outputId": "f269fa97-c9ae-45d7-cdd5-37c1bcbdc707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (3.1.5)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.10.2)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.6.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (75.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.5.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim->pyLDAvis) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->pyLDAvis) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.17.2)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.11/dist-packages (1.9.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from wordcloud) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from wordcloud) (11.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (2.14.1)\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "# Download stop words list and punkt tokenizer (if not previously downloaded)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "!pip install gensim\n",
        "!pip install pyLDAvis\n",
        "!pip install wordcloud matplotlib\n",
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from collections import defaultdict, Counter\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "aAVuaTpgTj7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P data/full_dataset/ https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_1.csv\n",
        "!wget -P data/full_dataset/ https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_2.csv\n",
        "!wget -P data/full_dataset/ https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_3.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8KYlS4YSkua",
        "outputId": "ea8c30cc-a109-4c2e-d553-561cae1dd2d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-24 10:52:58--  https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_1.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.31.207, 142.251.111.207, 142.251.179.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.31.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14174600 (14M) [application/octet-stream]\n",
            "Saving to: ‚Äòdata/full_dataset/goemotions_1.csv.2‚Äô\n",
            "\n",
            "goemotions_1.csv.2  100%[===================>]  13.52M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-02-24 10:52:59 (122 MB/s) - ‚Äòdata/full_dataset/goemotions_1.csv.2‚Äô saved [14174600/14174600]\n",
            "\n",
            "--2025-02-24 10:52:59--  https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_2.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.31.207, 142.251.111.207, 142.251.179.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.31.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14173154 (14M) [application/octet-stream]\n",
            "Saving to: ‚Äòdata/full_dataset/goemotions_2.csv.2‚Äô\n",
            "\n",
            "goemotions_2.csv.2  100%[===================>]  13.52M  79.5MB/s    in 0.2s    \n",
            "\n",
            "2025-02-24 10:52:59 (79.5 MB/s) - ‚Äòdata/full_dataset/goemotions_2.csv.2‚Äô saved [14173154/14173154]\n",
            "\n",
            "--2025-02-24 10:52:59--  https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_3.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.31.207, 142.251.111.207, 142.251.179.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.31.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14395164 (14M) [application/octet-stream]\n",
            "Saving to: ‚Äòdata/full_dataset/goemotions_3.csv.2‚Äô\n",
            "\n",
            "goemotions_3.csv.2  100%[===================>]  13.73M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-02-24 10:52:59 (115 MB/s) - ‚Äòdata/full_dataset/goemotions_3.csv.2‚Äô saved [14395164/14395164]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "goemotions_1 = pd.read_csv('data/full_dataset/goemotions_1.csv')\n",
        "goemotions_2 = pd.read_csv('data/full_dataset/goemotions_2.csv')\n",
        "goemotions_3 = pd.read_csv('data/full_dataset/goemotions_3.csv')\n",
        "\n",
        "combined_df = pd.concat([goemotions_1, goemotions_2, goemotions_3], ignore_index=True)\n",
        "emotion_columns = combined_df.columns[9:]\n",
        "\n",
        "combined_df['created_utc'] = pd.to_datetime(combined_df['created_utc'], unit='s', errors='coerce')\n",
        "combined_df.to_csv('data/full_dataset/goemotions_combined.csv', index=False)"
      ],
      "metadata": {
        "id": "3Q596tfwSoaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#emoji"
      ],
      "metadata": {
        "id": "qUeauS4-SvdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import emoji\n",
        "\n",
        "# Dictionary to store emojis with their positions, texts, and associated labels (emotions)\n",
        "emoji_dict = {}\n",
        "\n",
        "# Function to extract emojis and build the dictionary with emotions\n",
        "def build_emoji_dict(df):\n",
        "    # Iterate through each row of the DataFrame\n",
        "    for idx, row in df.iterrows():\n",
        "        text = row['text']\n",
        "\n",
        "        # Iterate through the emotion columns\n",
        "        for emotion_column in emotion_columns:\n",
        "            if row[emotion_column] == 1:  # Check if the emotion is present\n",
        "                emotion = emotion_column  # Get the emotion from the column name\n",
        "\n",
        "                # Iterate through each character in the text to check for emojis\n",
        "                for char in text:\n",
        "                    if emoji.is_emoji(char):\n",
        "                        if char not in emoji_dict:\n",
        "                            emoji_dict[char] = {'texts': [], 'emotion_count': {}}\n",
        "                        emoji_dict[char]['texts'].append((idx, text))\n",
        "\n",
        "                        # Update the emotion count for the current emoji\n",
        "                        if emotion not in emoji_dict[char]['emotion_count']:\n",
        "                            emoji_dict[char]['emotion_count'][emotion] = 0\n",
        "                        emoji_dict[char]['emotion_count'][emotion] += 1\n",
        "\n",
        "build_emoji_dict(combined_df)\n",
        "emoji_summary = []\n",
        "\n",
        "# Populate the summary DataFrame with emoji and their associated emotions\n",
        "for emoji_char, emotions in emoji_dict.items():\n",
        "    row = {'Emoji': emoji_char}\n",
        "    row.update(emotions)  # Add emotion counts to the row\n",
        "    emoji_summary.append(row)\n",
        "\n",
        "# Create the DataFrame from the list of rows\n",
        "emoji_df = pd.DataFrame(emoji_summary)\n",
        "\n",
        "# Display the resulting table\n",
        "print(emoji_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veYiDXmUS34D",
        "outputId": "ade36e8f-21bb-4190-bc39-bd43d401fdfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Emoji                                              texts  \\\n",
            "0       üòá  [(102, Nice! You and her would get along i bet...   \n",
            "1       ü§î  [(132, Funny, the right only seems to say this...   \n",
            "2       üòç  [(168, I love this sub reddit üòçüòÇ), (416, Looks...   \n",
            "3       üòÇ  [(168, I love this sub reddit üòçüòÇ), (340, I'm s...   \n",
            "4       ü§£  [(246, That‚Äôs what‚Äôs it‚Äôs called or what SHE‚ÄôS...   \n",
            "..    ...                                                ...   \n",
            "257     üê¢  [(146943, It took me 14 years to secure my AA ...   \n",
            "258     üöÄ  [(148977, Haha, thanks, bot! How's your day go...   \n",
            "259     üçß  [(151078, How are you all losing weight post-s...   \n",
            "260     üí•  [(156936, üòÇüòÇüë∏üë∏üëèüôåüëèüôå‚ù§‚ù§‚ù§üí•üí•üëëüëëüíéüíéüíØüíØ‚ôÄÔ∏è‚ôÄÔ∏è‚ôÄÔ∏è Now that's...   \n",
            "261     üçë  [(158002, Highkey tho! He got ass! üçë), (200908...   \n",
            "\n",
            "                                         emotion_count  \n",
            "0    {'neutral': 3, 'realization': 1, 'surprise': 1...  \n",
            "1    {'amusement': 9, 'confusion': 17, 'approval': ...  \n",
            "2    {'love': 29, 'admiration': 35, 'neutral': 20, ...  \n",
            "3    {'love': 76, 'disappointment': 38, 'approval':...  \n",
            "4    {'curiosity': 17, 'disappointment': 11, 'appro...  \n",
            "..                                                 ...  \n",
            "257                   {'neutral': 1, 'realization': 2}  \n",
            "258   {'amusement': 1, 'curiosity': 3, 'gratitude': 3}  \n",
            "259  {'curiosity': 2, 'realization': 1, 'annoyance'...  \n",
            "260  {'approval': 4, 'love': 2, 'excitement': 2, 'n...  \n",
            "261                      {'neutral': 1, 'approval': 1}  \n",
            "\n",
            "[262 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emoji_dict['ü§≠']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8eDye5ia4o2",
        "outputId": "280e1bf5-de3f-4a5e-8c8b-63e2872ccb43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'texts': [(39569,\n",
              "   'But then you missed their officiant who looks and sounds like [NAME]! ü§≠üò≥ü§£ '),\n",
              "  (128263,\n",
              "   'But then you missed their officiant who looks and sounds like [NAME]! ü§≠üò≥ü§£ '),\n",
              "  (147449,\n",
              "   'But then you missed their officiant who looks and sounds like [NAME]! ü§≠üò≥ü§£ ')],\n",
              " 'emotion_count': {'neutral': 3}}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emoji_df[['Emoji','emotion_count']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "H4SeX1AOacD3",
        "outputId": "a3678305-1b47-419a-9389-ecfbfe0d536e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Emoji                                      emotion_count\n",
              "0       üòá  {'neutral': 3, 'realization': 1, 'surprise': 1...\n",
              "1       ü§î  {'amusement': 9, 'confusion': 17, 'approval': ...\n",
              "2       üòç  {'love': 29, 'admiration': 35, 'neutral': 20, ...\n",
              "3       üòÇ  {'love': 76, 'disappointment': 38, 'approval':...\n",
              "4       ü§£  {'curiosity': 17, 'disappointment': 11, 'appro...\n",
              "..    ...                                                ...\n",
              "257     üê¢                   {'neutral': 1, 'realization': 2}\n",
              "258     üöÄ   {'amusement': 1, 'curiosity': 3, 'gratitude': 3}\n",
              "259     üçß  {'curiosity': 2, 'realization': 1, 'annoyance'...\n",
              "260     üí•  {'approval': 4, 'love': 2, 'excitement': 2, 'n...\n",
              "261     üçë                      {'neutral': 1, 'approval': 1}\n",
              "\n",
              "[262 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3d64197-7035-41a0-8742-2c67fb63b367\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Emoji</th>\n",
              "      <th>emotion_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>üòá</td>\n",
              "      <td>{'neutral': 3, 'realization': 1, 'surprise': 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ü§î</td>\n",
              "      <td>{'amusement': 9, 'confusion': 17, 'approval': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>üòç</td>\n",
              "      <td>{'love': 29, 'admiration': 35, 'neutral': 20, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>üòÇ</td>\n",
              "      <td>{'love': 76, 'disappointment': 38, 'approval':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ü§£</td>\n",
              "      <td>{'curiosity': 17, 'disappointment': 11, 'appro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>üê¢</td>\n",
              "      <td>{'neutral': 1, 'realization': 2}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>üöÄ</td>\n",
              "      <td>{'amusement': 1, 'curiosity': 3, 'gratitude': 3}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>üçß</td>\n",
              "      <td>{'curiosity': 2, 'realization': 1, 'annoyance'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>üí•</td>\n",
              "      <td>{'approval': 4, 'love': 2, 'excitement': 2, 'n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>üçë</td>\n",
              "      <td>{'neutral': 1, 'approval': 1}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows √ó 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3d64197-7035-41a0-8742-2c67fb63b367')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a3d64197-7035-41a0-8742-2c67fb63b367 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a3d64197-7035-41a0-8742-2c67fb63b367');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-262dda3b-32ea-4c91-9853-f4175ff3331e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-262dda3b-32ea-4c91-9853-f4175ff3331e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-262dda3b-32ea-4c91-9853-f4175ff3331e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"emoji_df[['Emoji','emotion_count']]\",\n  \"rows\": 262,\n  \"fields\": [\n    {\n      \"column\": \"Emoji\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 262,\n        \"samples\": [\n          \"\\ud83d\\ude41\",\n          \"\\ud83e\\udd1f\",\n          \"\\ud83d\\udcad\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion_count\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_emotions(emotion_count):\n",
        "    total_count = sum(emotion_count.values())\n",
        "    return {emotion: count / total_count for emotion, count in emotion_count.items()}\n",
        "\n",
        "\n",
        "emoji_df['normalized_emotion_count'] = emoji_df['emotion_count'].apply(normalize_emotions)\n",
        "\n",
        "emotion_columns = set()\n",
        "for emotion_count in emoji_df['normalized_emotion_count']:\n",
        "    emotion_columns.update(emotion_count.keys())\n",
        "\n",
        "# ◊¶◊ï◊® ◊ê◊™ ◊î◊û◊ò◊®◊ô◊¶◊î\n",
        "emotion_matrix = pd.DataFrame(columns=sorted(emotion_columns))\n",
        "\n",
        "# ◊û◊ú◊ê ◊ê◊™ ◊î◊û◊ò◊®◊ô◊¶◊î ◊¢◊ë◊ï◊® ◊õ◊ú ◊ê◊ô◊û◊ï◊í'◊ô\n",
        "for idx, row in emoji_df.iterrows():\n",
        "    emoji = row['Emoji']\n",
        "    normalized_counts = row['normalized_emotion_count']\n",
        "    emotion_matrix.loc[emoji] = [normalized_counts.get(emotion, 0) for emotion in emotion_matrix.columns]\n",
        "\n",
        "# ◊î◊¶◊í ◊ê◊™ ◊î◊û◊ò◊®◊ô◊¶◊î\n",
        "print(emotion_matrix)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNq8qbQChHuE",
        "outputId": "d336cb0a-51c4-491a-f108-c8b6ca1d1e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    admiration  amusement     anger  annoyance  approval    caring  confusion  \\\n",
            "üòá     0.111111   0.055556  0.000000   0.000000  0.055556  0.000000   0.055556   \n",
            "ü§î     0.022222   0.050000  0.033333   0.066667  0.072222  0.005556   0.094444   \n",
            "üòç     0.198864   0.011364  0.000000   0.000000  0.045455  0.011364   0.000000   \n",
            "üòÇ     0.044614   0.175271  0.015296   0.048438  0.112173  0.010198   0.019120   \n",
            "ü§£     0.126984   0.176871  0.029478   0.027211  0.063492  0.011338   0.004535   \n",
            "..         ...        ...       ...        ...       ...       ...        ...   \n",
            "üê¢     0.000000   0.000000  0.000000   0.000000  0.000000  0.000000   0.000000   \n",
            "üöÄ     0.000000   0.142857  0.000000   0.000000  0.000000  0.000000   0.000000   \n",
            "üçß     0.000000   0.000000  0.000000   0.250000  0.000000  0.000000   0.000000   \n",
            "üí•     0.000000   0.000000  0.000000   0.000000  0.400000  0.000000   0.000000   \n",
            "üçë     0.000000   0.000000  0.000000   0.000000  0.500000  0.000000   0.000000   \n",
            "\n",
            "    curiosity    desire  disappointment  ...      love  nervousness   neutral  \\\n",
            "üòá    0.166667  0.000000        0.000000  ...  0.166667     0.000000  0.166667   \n",
            "ü§î    0.133333  0.011111        0.022222  ...  0.000000     0.005556  0.200000   \n",
            "üòç    0.073864  0.017045        0.000000  ...  0.164773     0.000000  0.113636   \n",
            "üòÇ    0.042065  0.007648        0.024219  ...  0.048438     0.002549  0.147865   \n",
            "ü§£    0.038549  0.009070        0.024943  ...  0.047619     0.000000  0.192744   \n",
            "..        ...       ...             ...  ...       ...          ...       ...   \n",
            "üê¢    0.000000  0.000000        0.000000  ...  0.000000     0.000000  0.333333   \n",
            "üöÄ    0.428571  0.000000        0.000000  ...  0.000000     0.000000  0.000000   \n",
            "üçß    0.500000  0.000000        0.000000  ...  0.000000     0.000000  0.000000   \n",
            "üí•    0.000000  0.000000        0.000000  ...  0.200000     0.000000  0.200000   \n",
            "üçë    0.000000  0.000000        0.000000  ...  0.000000     0.000000  0.500000   \n",
            "\n",
            "    optimism     pride  realization    relief   remorse   sadness  surprise  \n",
            "üòá   0.000000  0.000000     0.055556  0.000000  0.000000  0.000000  0.055556  \n",
            "ü§î   0.033333  0.000000     0.055556  0.000000  0.000000  0.016667  0.038889  \n",
            "üòç   0.045455  0.000000     0.022727  0.000000  0.000000  0.005682  0.056818  \n",
            "üòÇ   0.040790  0.003187     0.043977  0.000000  0.000637  0.022945  0.026131  \n",
            "ü§£   0.027211  0.002268     0.065760  0.002268  0.009070  0.043084  0.024943  \n",
            "..       ...       ...          ...       ...       ...       ...       ...  \n",
            "üê¢   0.000000  0.000000     0.666667  0.000000  0.000000  0.000000  0.000000  \n",
            "üöÄ   0.000000  0.000000     0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "üçß   0.000000  0.000000     0.250000  0.000000  0.000000  0.000000  0.000000  \n",
            "üí•   0.000000  0.000000     0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "üçë   0.000000  0.000000     0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "\n",
            "[262 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "emotion_columns = list(set([key for emo_dict in emoji_df['emotion_count'] for key in emo_dict.keys()]))\n",
        "emotion_matrix = pd.DataFrame(0, index=emoji_df['Emoji'], columns=emotion_columns)\n",
        "\n",
        "for idx, row in emoji_df.iterrows():\n",
        "    emoji = row['Emoji']\n",
        "    emotion_counts = row['emotion_count']\n",
        "    total_count = sum(emotion_counts.values())\n",
        "    for emotion, count in emotion_counts.items():\n",
        "        emotion_matrix.loc[emoji, emotion] = count / total_count\n",
        "\n",
        "cosine_sim = cosine_similarity(emotion_matrix)\n",
        "\n",
        "cosine_sim_df = pd.DataFrame(cosine_sim, index=emotion_matrix.index, columns=emotion_matrix.index)\n",
        "\n",
        "plt.figure(figsize=(500, 400))\n",
        "sns.heatmap(cosine_sim_df, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
        "\n",
        "plt.title(\"Emoji Similarity Based on Emotional Distribution\", fontsize=100)\n",
        "plt.xlabel(\"Emojis\", fontsize=88)\n",
        "plt.ylabel(\"Emojis\", fontsize=88)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiKuFKbMhIOU",
        "outputId": "47c3ee25-6c0c-4b8e-9d54-ad08508ec07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.16666666666666666' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.05555555555555555' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.05555555555555555' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.16666666666666666' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.16666666666666666' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.1111111111111111' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.05555555555555555' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.05555555555555555' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.05555555555555555' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.05555555555555555' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.05555555555555555' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.06666666666666667' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.022222222222222223' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.011111111111111112' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.07222222222222222' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.03333333333333333' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.005555555555555556' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.005555555555555556' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.011111111111111112' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.03333333333333333' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.016666666666666666' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.016666666666666666' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.011111111111111112' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.005555555555555556' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.017208413001912046' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0006373486297004461' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0031867431485022306' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "<ipython-input-7-fee29c2b2089>:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0022675736961451248' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  emotion_matrix.loc[emoji, emotion] = count / total_count\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129300 (\\N{THINKING FACE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129315 (\\N{ROLLING ON THE FLOOR LAUGHING}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129314 (\\N{NAUSEATED FACE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129335 (\\N{SHRUG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127995 (\\N{EMOJI MODIFIER FITZPATRICK TYPE-1-2}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128128 (\\N{SKULL}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128105 (\\N{WOMAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128132 (\\N{LIPSTICK}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128139 (\\N{KISS MARK}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127775 (\\N{GLOWING STAR}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 10024 (\\N{SPARKLES}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128683 (\\N{NO ENTRY SIGN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128175 (\\N{HUNDRED POINTS SYMBOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128548 (\\N{FACE WITH LOOK OF TRIUMPH}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128114 (\\N{MAN WITH GUA PI MAO}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128121 (\\N{JAPANESE OGRE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128240 (\\N{NEWSPAPER}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127981 (\\N{FACTORY}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128077 (\\N{THUMBS UP SIGN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128511 (\\N{MOYAI}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127926 (\\N{MULTIPLE MUSICAL NOTES}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127925 (\\N{MUSICAL NOTE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128579 (\\N{UPSIDE-DOWN FACE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128168 (\\N{DASH SYMBOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128588 (\\N{PERSON RAISING BOTH HANDS IN CELEBRATION}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127887 (\\N{CARP STREAMER}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127793 (\\N{SEEDLING}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127345 (\\N{NEGATIVE SQUARED LATIN CAPITAL LETTER B}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128150 (\\N{SPARKLING HEART}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128293 (\\N{FIRE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128156 (\\N{PURPLE HEART}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128591 (\\N{PERSON WITH FOLDED HANDS}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127997 (\\N{EMOJI MODIFIER FITZPATRICK TYPE-4}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129326 (\\N{FACE WITH OPEN MOUTH VOMITING}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128153 (\\N{BLUE HEART}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127829 (\\N{SLICE OF PIZZA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128580 (\\N{FACE WITH ROLLING EYES}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128076 (\\N{OK HAND SIGN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129330 (\\N{PALMS UP TOGETHER}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129318 (\\N{FACE PALM}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127996 (\\N{EMOJI MODIFIER FITZPATRICK TYPE-3}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128064 (\\N{EYES}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128149 (\\N{TWO HEARTS}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129303 (\\N{HUGGING FACE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128079 (\\N{CLAPPING HANDS SIGN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128003 (\\N{WATER BUFFALO}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128141 (\\N{RING}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129321 (\\N{GRINNING FACE WITH STAR EYES}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129327 (\\N{SHOCKED FACE WITH EXPLODING HEAD}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129431 (\\N{CRICKET}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128166 (\\N{SPLASHING SWEAT SYMBOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127881 (\\N{PARTY POPPER}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128131 (\\N{DANCER}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128155 (\\N{YELLOW HEART}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128147 (\\N{BEATING HEART}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129301 (\\N{FACE WITH HEAD-BANDAGE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128581 (\\N{FACE WITH NO GOOD GESTURE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129322 (\\N{GRINNING FACE WITH ONE LARGE AND ONE SMALL EYE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129312 (\\N{FACE WITH COWBOY HAT}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129310 (\\N{HAND WITH INDEX AND MIDDLE FINGERS CROSSED}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129297 (\\N{MONEY-MOUTH FACE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128074 (\\N{FISTED HAND SIGN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128578 (\\N{SLIGHTLY SMILING FACE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129461 (\\N{LEG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128176 (\\N{MONEY BAG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128586 (\\N{SPEAK-NO-EVIL MONKEY}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129328 (\\N{PREGNANT WOMAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128170 (\\N{FLEXED BICEPS}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128116 (\\N{OLDER MAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128129 (\\N{INFORMATION DESK PERSON}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127880 (\\N{BALLOON}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128154 (\\N{GREEN HEART}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127987 (\\N{WAVING WHITE FLAG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127752 (\\N{RAINBOW}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127754 (\\N{WATER WAVE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127871 (\\N{POPCORN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127946 (\\N{SWIMMER}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128590 (\\N{PERSON WITH POUTING FACE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129368 (\\N{SHALLOW PAN OF FOOD}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127849 (\\N{DOUGHNUT}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128151 (\\N{GROWING HEART}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128010 (\\N{CROCODILE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127344 (\\N{NEGATIVE SQUARED LATIN CAPITAL LETTER A}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 9935 (\\N{PICK}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128142 (\\N{GEM STONE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127808 (\\N{FOUR LEAF CLOVER}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127821 (\\N{PINEAPPLE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128273 (\\N{KEY}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129316 (\\N{DROOLING FACE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129499 (\\N{VAMPIRE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128737 (\\N{SHIELD}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127998 (\\N{EMOJI MODIFIER FITZPATRICK TYPE-5}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129505 (\\N{ORANGE HEART}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129299 (\\N{NERD FACE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129324 (\\N{SERIOUS FACE WITH SYMBOLS COVERING MOUTH}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128118 (\\N{BABY}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129416 (\\N{SHARK}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 9994 (\\N{RAISED FIST}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127809 (\\N{MAPLE LEAF}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129305 (\\N{CALL ME HAND}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127867 (\\N{CLINKING BEER MUGS}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127856 (\\N{SHORTCAKE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 11093 (\\N{HEAVY LARGE CIRCLE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 9937 (\\N{HELMET WITH WHITE CROSS}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128120 (\\N{PRINCESS}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128420 (\\N{BLACK HEART}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128083 (\\N{EYEGLASSES}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127866 (\\N{BEER MUG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128582 (\\N{FACE WITH OK GESTURE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129304 (\\N{SIGN OF THE HORNS}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127801 (\\N{ROSE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127870 (\\N{BOTTLE WITH POPPING CORK}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128073 (\\N{WHITE RIGHT POINTING BACKHAND INDEX}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129306 (\\N{RAISED BACK OF HAND}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128400 (\\N{RAISED HAND WITH FINGERS SPLAYED}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128075 (\\N{WAVING HAND SIGN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128080 (\\N{OPEN HANDS SIGN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127894 (\\N{MILITARY MEDAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128556 (\\N{GRIMACING FACE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128584 (\\N{SEE-NO-EVIL MONKEY}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127934 (\\N{TENNIS RACQUET AND BALL}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128081 (\\N{CROWN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128123 (\\N{GHOST}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129325 (\\N{SMILING FACE WITH SMILING EYES AND HAND COVERING MOUTH}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128378 (\\N{MAN DANCING}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129408 (\\N{CRAB}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127807 (\\N{HERB}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128173 (\\N{THOUGHT BALLOON}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129371 (\\N{GLASS OF MILK}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128658 (\\N{FIRE ENGINE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127874 (\\N{BIRTHDAY CAKE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129365 (\\N{CARROT}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128161 (\\N{ELECTRIC LIGHT BULB}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128148 (\\N{BROKEN HEART}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128021 (\\N{DOG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129392 (\\N{SMILING FACE WITH SMILING EYES AND THREE HEARTS}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129320 (\\N{FACE WITH ONE EYEBROW RAISED}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129488 (\\N{FACE WITH MONOCLE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128421 (\\N{DESKTOP COMPUTER}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128721 (\\N{OCTAGONAL SIGN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 9995 (\\N{RAISED HAND}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128069 (\\N{TONGUE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128133 (\\N{NAIL POLISH}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129307 (\\N{LEFT-FACING FIST}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129311 (\\N{I LOVE YOU HAND SIGN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128406 (\\N{RAISED HAND WITH PART BETWEEN MIDDLE AND RING FINGERS}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128071 (\\N{WHITE DOWN POINTING BACKHAND INDEX}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128134 (\\N{FACE MASSAGE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129402 (\\N{FACE WITH PLEADING EYES}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128298 (\\N{HOCHO}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127820 (\\N{BANANA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128218 (\\N{BOOKS}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128169 (\\N{PILE OF POO}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129346 (\\N{CLINKING GLASSES}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128405 (\\N{REVERSED HAND WITH MIDDLE FINGER EXTENDED}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129344 (\\N{WILTED FLOWER}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128659 (\\N{POLICE CAR}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127944 (\\N{AMERICAN FOOTBALL}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129323 (\\N{FACE WITH FINGER COVERING CLOSED LIPS}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128065 (\\N{EYE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 11088 (\\N{WHITE MEDIUM STAR}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128078 (\\N{THUMBS DOWN SIGN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127999 (\\N{EMOJI MODIFIER FITZPATRICK TYPE-6}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127853 (\\N{LOLLIPOP}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127814 (\\N{AUBERGINE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129494 (\\N{PERSON IN STEAMY ROOM}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128587 (\\N{HAPPY PERSON RAISING ONE HAND}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128104 (\\N{MAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129308 (\\N{RIGHT-FACING FIST}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128113 (\\N{PERSON WITH BLOND HAIR}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129317 (\\N{LYING FACE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129319 (\\N{SNEEZING FACE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128577 (\\N{SLIGHTLY FROWNING FACE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 129472 (\\N{CHEESE WEDGE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127907 (\\N{FISHING POLE AND FISH}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128178 (\\N{HEAVY DOLLAR SIGN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128184 (\\N{MONEY WITH WINGS}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128465 (\\N{WASTEBASKET}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128007 (\\N{RABBIT}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127873 (\\N{WRAPPED PRESENT}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128034 (\\N{TURTLE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128640 (\\N{ROCKET}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127847 (\\N{SHAVED ICE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 128165 (\\N{COLLISION SYMBOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 127825 (\\N{PEACH}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OIMWTBihejEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#preprocess"
      ],
      "metadata": {
        "id": "JZBs_sRZTdFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text, stop_words):\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'_', ' ', text)\n",
        "    words = text.lower().split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    return words\n",
        "\n",
        "negation_words = [\"not\", \"no\", \"never\", \"none\", \"nobody\", \"nothing\", \"neither\", \"nor\", \"nowhere\", \"isn't\", \"aren't\", \"wasn't\", \"weren't\", \"don't\", \"doesn't\", \"didn't\", \"won't\", \"wouldn't\", \"shan't\", \"shouldn't\", \"can't\", \"cannot\", \"couldn't\", \"mightn't\", \"mustn't\",\"don't\"]\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "custom_stop_words = [word for word in stop_words if word not in negation_words]\n",
        "\n",
        "combined_df['preprocessed_text'] = combined_df['text'].apply(lambda x: preprocess_text(x, custom_stop_words))"
      ],
      "metadata": {
        "id": "PDG8YEPJTckY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df[['text','preprocessed_text']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "I3mqnpEjT1MB",
        "outputId": "717f8660-d60c-430e-b60c-fe144e7cfe26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text  \\\n",
              "0                                         That game hurt.   \n",
              "1        >sexuality shouldn‚Äôt be a grouping category I...   \n",
              "2          You do right, if you don't care then fuck 'em!   \n",
              "3                                      Man I love reddit.   \n",
              "4       [NAME] was nowhere near them, he was by the Fa...   \n",
              "...                                                   ...   \n",
              "211220                             Everyone likes [NAME].   \n",
              "211221  Well when you‚Äôve imported about a gazillion of...   \n",
              "211222                                 That looks amazing   \n",
              "211223  The FDA has plenty to criticize. But like here...   \n",
              "211224  Desktop link: ^^/r/HelperBot_ ^^Downvote ^^to ...   \n",
              "\n",
              "                                        preprocessed_text  \n",
              "0                                            [game, hurt]  \n",
              "1       [sexuality, grouping, category, makes, differe...  \n",
              "2                                 [right, care, fuck, em]  \n",
              "3                                     [man, love, reddit]  \n",
              "4                           [name, nowhere, near, falcon]  \n",
              "...                                                   ...  \n",
              "211220                            [everyone, likes, name]  \n",
              "211221  [well, imported, gazillion, country, gets, ser...  \n",
              "211222                                   [looks, amazing]  \n",
              "211223  [fda, plenty, criticize, like, usually, critic...  \n",
              "211224  [desktop, link, r, helperbot, downvote, remove...  \n",
              "\n",
              "[211225 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3596b50-8be0-462a-90ac-890cac33a000\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>preprocessed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>That game hurt.</td>\n",
              "      <td>[game, hurt]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&gt;sexuality shouldn‚Äôt be a grouping category I...</td>\n",
              "      <td>[sexuality, grouping, category, makes, differe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>You do right, if you don't care then fuck 'em!</td>\n",
              "      <td>[right, care, fuck, em]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Man I love reddit.</td>\n",
              "      <td>[man, love, reddit]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
              "      <td>[name, nowhere, near, falcon]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211220</th>\n",
              "      <td>Everyone likes [NAME].</td>\n",
              "      <td>[everyone, likes, name]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211221</th>\n",
              "      <td>Well when you‚Äôve imported about a gazillion of...</td>\n",
              "      <td>[well, imported, gazillion, country, gets, ser...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211222</th>\n",
              "      <td>That looks amazing</td>\n",
              "      <td>[looks, amazing]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211223</th>\n",
              "      <td>The FDA has plenty to criticize. But like here...</td>\n",
              "      <td>[fda, plenty, criticize, like, usually, critic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211224</th>\n",
              "      <td>Desktop link: ^^/r/HelperBot_ ^^Downvote ^^to ...</td>\n",
              "      <td>[desktop, link, r, helperbot, downvote, remove...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>211225 rows √ó 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3596b50-8be0-462a-90ac-890cac33a000')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b3596b50-8be0-462a-90ac-890cac33a000 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b3596b50-8be0-462a-90ac-890cac33a000');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b0c99c0f-1c5e-4233-b6b1-8ec5d5413f6c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0c99c0f-1c5e-4233-b6b1-8ec5d5413f6c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b0c99c0f-1c5e-4233-b6b1-8ec5d5413f6c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def build_emotion_word_dict(dataframe, text_column, emotion_columns):\n",
        "    \"\"\"\n",
        "    Builds a dictionary where each key is an emotion, and the value is a list of unique words\n",
        "    that appeared in texts associated with that emotion.\n",
        "\n",
        "    :param dataframe: DataFrame containing a text column and emotion columns.\n",
        "    :param text_column: The name of the column containing the text data.\n",
        "    :param emotion_columns: A list of columns representing emotions.\n",
        "    :return: A dictionary mapping emotions to lists of words.\n",
        "    \"\"\"\n",
        "    # Initialize a defaultdict with lists\n",
        "    emotion_word_dict = defaultdict(list)\n",
        "\n",
        "    # Iterate over each row in the DataFrame\n",
        "    for _, row in dataframe.iterrows():\n",
        "        # Extract the words from the text column\n",
        "        text_words = row[text_column]\n",
        "        for emotion in emotion_columns:\n",
        "            if row[emotion] == 1:  # Check if the emotion is associated with this text\n",
        "                emotion_word_dict[emotion].extend(text_words)\n",
        "\n",
        "    # Remove duplicate words for each emotion\n",
        "    # for emotion, words in emotion_word_dict.items():\n",
        "    #     emotion_word_dict[emotion] = list(set(words))\n",
        "\n",
        "    return emotion_word_dict\n",
        "\n",
        "# Example usage\n",
        "emotion_word_dict = build_emotion_word_dict(combined_df, text_column='preprocessed_text', emotion_columns=emotion_columns)\n"
      ],
      "metadata": {
        "id": "bW5-i6GXWbIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "import re\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, TfidfVectorizer\n",
        "\n",
        "def get_common_words(subreddit_texts, stop_words=set(), top_n=10):\n",
        "    all_text = \" \".join(subreddit_texts)\n",
        "    words = re.findall(r'\\b[a-zA-Z]+\\b', all_text.lower())\n",
        "    words = [w for w in words if w not in stop_words]\n",
        "    return Counter(words).most_common(top_n)\n",
        "\n",
        "def get_ngrams(subreddit_texts, n=2, stop_words=set(), top_n=10):\n",
        "    all_text = \" \".join(subreddit_texts)\n",
        "    words = re.findall(r'\\b[a-zA-Z]+\\b', all_text.lower())\n",
        "    words = [w for w in words if w not in stop_words]\n",
        "    ngrams = zip(*[words[i:] for i in range(n)])\n",
        "    return Counter([\" \".join(ngram) for ngram in ngrams]).most_common(top_n)\n",
        "\n",
        "def get_tfidf(subreddit_texts, top_n=10):\n",
        "    vectorizer = TfidfVectorizer(stop_words='english', max_features=top_n)\n",
        "    tfidf_matrix = vectorizer.fit_transform(subreddit_texts)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    scores = tfidf_matrix.sum(axis=0).A1\n",
        "    return sorted(zip(feature_names, scores), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "def plot_word_frequencies(subreddit_texts, subreddit_name):\n",
        "    word_counts = get_common_words(subreddit_texts)\n",
        "    if not word_counts:\n",
        "        print(f\"No significant words found for subreddit {subreddit_name}\")\n",
        "        return\n",
        "\n",
        "    words, counts = zip(*word_counts)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.bar(words, counts, color='skyblue', edgecolor='black')\n",
        "    plt.xlabel(\"Words\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(f\"Most Common Words in r/{subreddit_name}\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "def build_word_network(subreddit_texts, subreddit_name):\n",
        "    all_text = \" \".join(subreddit_texts)\n",
        "    words = re.findall(r'\\b[a-zA-Z]+\\b', all_text)\n",
        "    words = [word.lower() for word in words if word.lower() not in ENGLISH_STOP_WORDS]\n",
        "\n",
        "    G = nx.Graph()\n",
        "    for i in range(len(words) - 1):\n",
        "        G.add_edge(words[i], words[i+1])\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    pos = nx.spring_layout(G, seed=42)\n",
        "    nx.draw(G, pos, node_size=20, edge_color='gray', alpha=0.7, with_labels=False)\n",
        "    plt.title(f\"Word Network Graph for r/{subreddit_name}\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "lb6D18OQWdjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def calculate_word_statistics(word_list, total_words_in_emotion, total_texts_in_emotion, total_texts):\n",
        "    \"\"\"\n",
        "    Calculates comprehensive word statistics including frequency, TF, log-TF, IDF, TF-IDF, and BM25.\n",
        "\n",
        "    :param word_list: List of words that appeared with a specific emotion.\n",
        "    :param total_words_in_emotion: Total number of words across all texts for the emotion.\n",
        "    :param total_texts_in_emotion: Total number of texts associated with the specific emotion.\n",
        "    :param total_texts: Total number of texts in the entire dataset.\n",
        "    :return: A DataFrame with the statistics for each word.\n",
        "    \"\"\"\n",
        "    # Count the frequency of each word\n",
        "    word_counts = Counter(word_list)\n",
        "\n",
        "    # Create a DataFrame with the word and its frequency\n",
        "    df = pd.DataFrame(word_counts.items(), columns=['Word', 'Frequency'])\n",
        "\n",
        "    # Calculate Term Frequency (TF)\n",
        "    df['TF'] = df['Frequency'] / total_words_in_emotion\n",
        "\n",
        "    # Calculate log-transformed TF (log-TF)\n",
        "    df['Log-TF'] = np.log1p(df['TF'])  # log1p to avoid log(0)\n",
        "\n",
        "    # Calculate Inverse Document Frequency (IDF)\n",
        "    df['IDF'] = np.log((total_texts + 1) / (total_texts_in_emotion + 1))  # Add 1 to avoid division by zero\n",
        "\n",
        "    # Calculate TF-IDF\n",
        "    df['TF-IDF'] = df['TF'] * df['IDF']\n",
        "\n",
        "    # Calculate BM25 components\n",
        "    k = 1.5  # Tunable parameter\n",
        "    b = 0.75  # Tunable parameter\n",
        "    avg_doc_length = total_words_in_emotion / total_texts_in_emotion\n",
        "    df['BM25'] = (df['Frequency'] * (k + 1)) / (df['Frequency'] + k * (1 - b + b * (total_words_in_emotion / avg_doc_length)))\n",
        "\n",
        "    # Calculate a custom importance metric (example: normalized frequency squared)\n",
        "    df['Custom-Metric'] = (df['Frequency'] / total_words_in_emotion) ** 2\n",
        "\n",
        "    return df.sort_values(by='Frequency', ascending=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B-Wel5KeXtc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_word_emotoin = []\n",
        "for i in emotion_columns:\n",
        "  dict_word = emotion_word_dict[i]\n",
        "  total_words = len(dict_word)\n",
        "  total_texts_in_i = combined_df[combined_df[i] == 1].shape[0]\n",
        "  total_texts = combined_df.shape[0]\n",
        "  word_statistics = calculate_word_statistics(dict_word, total_words,total_texts_in_i,total_texts)\n",
        "\n",
        "  list_word_emotoin.append(word_statistics)"
      ],
      "metadata": {
        "id": "tD-BbNIxZ21b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(list_word_emotoin)):\n",
        "  print(emotion_columns[i])\n",
        "  print(list_word_emotoin[i].head(10))"
      ],
      "metadata": {
        "id": "6tumcrTraQBQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a98cf165-f1b6-4b02-b9b2-6afc4ed2017b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "admiration\n",
            "        Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "30      name       3202  0.028757  0.028352  2.511981  0.072238  0.356177   \n",
            "1       good       2372  0.021303  0.021079  2.511981  0.053513  0.273969   \n",
            "88     great       1984  0.017818  0.017662  2.511981  0.044760  0.233338   \n",
            "22      like       1446  0.012987  0.012903  2.511981  0.032622  0.174480   \n",
            "47      love       1107  0.009942  0.009893  2.511981  0.024974  0.135797   \n",
            "109  awesome        951  0.008541  0.008505  2.511981  0.021455  0.117560   \n",
            "6        one        945  0.008487  0.008451  2.511981  0.021320  0.116853   \n",
            "151  amazing        870  0.007814  0.007783  2.511981  0.019627  0.107979   \n",
            "63    really        862  0.007742  0.007712  2.511981  0.019447  0.107029   \n",
            "43      best        851  0.007643  0.007614  2.511981  0.019199  0.105721   \n",
            "\n",
            "     Custom-Metric  \n",
            "30        0.000827  \n",
            "1         0.000454  \n",
            "88        0.000317  \n",
            "22        0.000169  \n",
            "47        0.000099  \n",
            "109       0.000073  \n",
            "6         0.000072  \n",
            "151       0.000061  \n",
            "63        0.000060  \n",
            "43        0.000058  \n",
            "amusement\n",
            "      Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "53     lol       3271  0.052030  0.050722  3.128738  0.162790  0.598120   \n",
            "95    name       1505  0.023939  0.023657  3.128738  0.074900  0.316017   \n",
            "20    haha        885  0.014077  0.013979  3.128738  0.044044  0.196039   \n",
            "192   like        786  0.012503  0.012425  3.128738  0.039117  0.175650   \n",
            "33   funny        724  0.011516  0.011451  3.128738  0.036032  0.162697   \n",
            "48     not        623  0.009910  0.009861  3.128738  0.031005  0.141283   \n",
            "78     fun        566  0.009003  0.008963  3.128738  0.028168  0.129023   \n",
            "40    lmao        478  0.007603  0.007575  3.128738  0.023789  0.109845   \n",
            "45     one        448  0.007126  0.007101  3.128738  0.022296  0.103235   \n",
            "276  would        395  0.006283  0.006263  3.128738  0.019658  0.091469   \n",
            "\n",
            "     Custom-Metric  \n",
            "53        0.002707  \n",
            "95        0.000573  \n",
            "20        0.000198  \n",
            "192       0.000156  \n",
            "33        0.000133  \n",
            "48        0.000098  \n",
            "78        0.000081  \n",
            "40        0.000058  \n",
            "45        0.000051  \n",
            "276       0.000039  \n",
            "anger\n",
            "        Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "112     name       1390  0.026194  0.025857  3.262918  0.085470  0.331430   \n",
            "35      fuck        809  0.015245  0.015130  3.262918  0.049745  0.204213   \n",
            "159      not        658  0.012400  0.012324  3.262918  0.040460  0.168668   \n",
            "174     hate        640  0.012061  0.011989  3.262918  0.039353  0.164358   \n",
            "81      like        560  0.010553  0.010498  3.262918  0.034434  0.145004   \n",
            "40   fucking        559  0.010534  0.010479  3.262918  0.034372  0.144761   \n",
            "110   people        544  0.010252  0.010199  3.262918  0.033450  0.141095   \n",
            "36        no        453  0.008537  0.008500  3.262918  0.027855  0.118613   \n",
            "196      get        426  0.008028  0.007996  3.262918  0.026194  0.111859   \n",
            "142     shit        282  0.005314  0.005300  3.262918  0.017340  0.075185   \n",
            "\n",
            "     Custom-Metric  \n",
            "112       0.000686  \n",
            "35        0.000232  \n",
            "159       0.000154  \n",
            "174       0.000145  \n",
            "81        0.000111  \n",
            "40        0.000111  \n",
            "110       0.000105  \n",
            "36        0.000073  \n",
            "196       0.000064  \n",
            "142       0.000028  \n",
            "annoyance\n",
            "       Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "27     name       2233  0.022620  0.022368  2.741463  0.062011  0.318025   \n",
            "15      not       1412  0.014303  0.014202  2.741463  0.039212  0.210965   \n",
            "36     like       1188  0.012034  0.011962  2.741463  0.032991  0.179906   \n",
            "38   people        936  0.009481  0.009437  2.741463  0.025993  0.143941   \n",
            "383      no        781  0.007911  0.007880  2.741463  0.021689  0.121261   \n",
            "209     get        720  0.007293  0.007267  2.741463  0.019995  0.112215   \n",
            "88      one        572  0.005794  0.005778  2.741463  0.015885  0.089979   \n",
            "284   would        507  0.005136  0.005123  2.741463  0.014080  0.080082   \n",
            "314  really        480  0.004862  0.004851  2.741463  0.013330  0.075946   \n",
            "132   think        463  0.004690  0.004679  2.741463  0.012858  0.073335   \n",
            "\n",
            "     Custom-Metric  \n",
            "27        0.000512  \n",
            "15        0.000205  \n",
            "36        0.000145  \n",
            "38        0.000090  \n",
            "383       0.000063  \n",
            "209       0.000053  \n",
            "88        0.000034  \n",
            "284       0.000026  \n",
            "314       0.000024  \n",
            "132       0.000022  \n",
            "approval\n",
            "       Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "146    name       2730  0.022079  0.021839  2.483837  0.054840  0.302622   \n",
            "2      like       1556  0.012584  0.012506  2.483837  0.031257  0.181955   \n",
            "173     not       1455  0.011767  0.011699  2.483837  0.029228  0.170952   \n",
            "214    good        982  0.007942  0.007911  2.483837  0.019726  0.118001   \n",
            "184     one        825  0.006672  0.006650  2.483837  0.016573  0.099889   \n",
            "30    right        804  0.006502  0.006481  2.483837  0.016151  0.097446   \n",
            "24      get        800  0.006470  0.006449  2.483837  0.016070  0.096980   \n",
            "167  people        769  0.006219  0.006200  2.483837  0.015448  0.093362   \n",
            "148   think        758  0.006130  0.006112  2.483837  0.015227  0.092076   \n",
            "233    yeah        746  0.006033  0.006015  2.483837  0.014986  0.090671   \n",
            "\n",
            "     Custom-Metric  \n",
            "146       0.000487  \n",
            "2         0.000158  \n",
            "173       0.000138  \n",
            "214       0.000063  \n",
            "184       0.000045  \n",
            "30        0.000042  \n",
            "24        0.000042  \n",
            "167       0.000039  \n",
            "148       0.000038  \n",
            "233       0.000036  \n",
            "caring\n",
            "       Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "20     name        779  0.018157  0.017994  3.561169  0.064661  0.258692   \n",
            "50      get        541  0.012610  0.012531  3.561169  0.044906  0.185522   \n",
            "1       not        529  0.012330  0.012255  3.561169  0.043910  0.181706   \n",
            "44     good        505  0.011771  0.011702  3.561169  0.041918  0.174036   \n",
            "55     like        380  0.008857  0.008818  3.561169  0.031542  0.133254   \n",
            "117  better        320  0.007459  0.007431  3.561169  0.026562  0.113166   \n",
            "57     hope        304  0.007086  0.007061  3.561169  0.025234  0.107752   \n",
            "67     feel        292  0.006806  0.006783  3.561169  0.024237  0.103675   \n",
            "16       no        282  0.006573  0.006551  3.561169  0.023407  0.100267   \n",
            "14       go        278  0.006480  0.006459  3.561169  0.023075  0.098901   \n",
            "\n",
            "     Custom-Metric  \n",
            "20        0.000330  \n",
            "50        0.000159  \n",
            "1         0.000152  \n",
            "44        0.000139  \n",
            "55        0.000078  \n",
            "117       0.000056  \n",
            "57        0.000050  \n",
            "67        0.000046  \n",
            "16        0.000043  \n",
            "14        0.000042  \n",
            "confusion\n",
            "       Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "41     name       1296  0.025412  0.025094  3.356869  0.085304  0.338372   \n",
            "15      not       1192  0.023373  0.023104  3.356869  0.078459  0.314636   \n",
            "96     know        663  0.013000  0.012916  3.356869  0.043639  0.185356   \n",
            "86     like        608  0.011922  0.011851  3.356869  0.040019  0.171032   \n",
            "97    think        508  0.009961  0.009912  3.356869  0.033437  0.144528   \n",
            "39     sure        480  0.009412  0.009368  3.356869  0.031594  0.136998   \n",
            "261      no        420  0.008235  0.008202  3.356869  0.027645  0.120700   \n",
            "65    would        386  0.007569  0.007540  3.356869  0.025407  0.111364   \n",
            "163  people        353  0.006922  0.006898  3.356869  0.023235  0.102233   \n",
            "127     get        335  0.006569  0.006547  3.356869  0.022050  0.097223   \n",
            "\n",
            "     Custom-Metric  \n",
            "41        0.000646  \n",
            "15        0.000546  \n",
            "96        0.000169  \n",
            "86        0.000142  \n",
            "97        0.000099  \n",
            "39        0.000089  \n",
            "261       0.000068  \n",
            "65        0.000057  \n",
            "163       0.000048  \n",
            "127       0.000043  \n",
            "curiosity\n",
            "        Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "98      name       1691  0.027014  0.026656  3.081525  0.083245  0.335652   \n",
            "41       not        779  0.012445  0.012368  3.081525  0.038349  0.166697   \n",
            "36      like        762  0.012173  0.012100  3.081525  0.037512  0.163297   \n",
            "106    would        606  0.009681  0.009634  3.081525  0.029832  0.131626   \n",
            "34      know        557  0.008898  0.008859  3.081525  0.027420  0.121500   \n",
            "118      get        443  0.007077  0.007052  3.081525  0.021808  0.097604   \n",
            "245   people        418  0.006678  0.006655  3.081525  0.020577  0.092299   \n",
            "198  curious        408  0.006518  0.006497  3.081525  0.020085  0.090171   \n",
            "123    think        404  0.006454  0.006433  3.081525  0.019888  0.089318   \n",
            "53       see        392  0.006262  0.006243  3.081525  0.019297  0.086757   \n",
            "\n",
            "     Custom-Metric  \n",
            "98        0.000730  \n",
            "41        0.000155  \n",
            "36        0.000148  \n",
            "106       0.000094  \n",
            "34        0.000079  \n",
            "118       0.000050  \n",
            "245       0.000045  \n",
            "198       0.000042  \n",
            "123       0.000042  \n",
            "53        0.000039  \n",
            "desire\n",
            "      Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "12    name        799  0.028203  0.027813  4.013202  0.113186  0.392166   \n",
            "13    wish        768  0.027109  0.026748  4.013202  0.108794  0.379259   \n",
            "9     want        515  0.018179  0.018015  4.013202  0.072954  0.267699   \n",
            "199   like        395  0.013943  0.013847  4.013202  0.055955  0.210577   \n",
            "41   would        367  0.012954  0.012871  4.013202  0.051989  0.196825   \n",
            "36    hope        332  0.011719  0.011651  4.013202  0.047031  0.179401   \n",
            "14     get        280  0.009884  0.009835  4.013202  0.039665  0.153022   \n",
            "57     not        263  0.009283  0.009241  4.013202  0.037256  0.144268   \n",
            "109  could        260  0.009178  0.009136  4.013202  0.036831  0.142716   \n",
            "363   need        236  0.008330  0.008296  4.013202  0.033432  0.130228   \n",
            "\n",
            "     Custom-Metric  \n",
            "12        0.000795  \n",
            "13        0.000735  \n",
            "9         0.000330  \n",
            "199       0.000194  \n",
            "41        0.000168  \n",
            "36        0.000137  \n",
            "14        0.000098  \n",
            "57        0.000086  \n",
            "109       0.000084  \n",
            "363       0.000069  \n",
            "disappointment\n",
            "       Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "50     name       1475  0.023491  0.023220  3.216398  0.075558  0.335136   \n",
            "2       not        948  0.015098  0.014985  3.216398  0.048562  0.226231   \n",
            "48     like        663  0.010559  0.010504  3.216398  0.033963  0.162644   \n",
            "249     bad        578  0.009205  0.009163  3.216398  0.029608  0.142984   \n",
            "74       no        536  0.008537  0.008500  3.216398  0.027457  0.133148   \n",
            "76      get        451  0.007183  0.007157  3.216398  0.023103  0.112987   \n",
            "8    really        444  0.007071  0.007046  3.216398  0.022744  0.111312   \n",
            "107     one        397  0.006323  0.006303  3.216398  0.020337  0.100000   \n",
            "241  people        389  0.006195  0.006176  3.216398  0.019927  0.098064   \n",
            "152   would        367  0.005845  0.005828  3.216398  0.018800  0.092724   \n",
            "\n",
            "     Custom-Metric  \n",
            "50        0.000552  \n",
            "2         0.000228  \n",
            "48        0.000111  \n",
            "249       0.000085  \n",
            "74        0.000073  \n",
            "76        0.000052  \n",
            "8         0.000050  \n",
            "107       0.000040  \n",
            "241       0.000038  \n",
            "152       0.000034  \n",
            "disapproval\n",
            "       Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "93      not       2679  0.032006  0.031505  2.917125  0.093367  0.431224   \n",
            "11     name       1720  0.020549  0.020341  2.917125  0.059944  0.295079   \n",
            "100      no       1423  0.017001  0.016858  2.917125  0.049593  0.249205   \n",
            "61     like       1018  0.012162  0.012089  2.917125  0.035479  0.183485   \n",
            "86    think        656  0.007837  0.007807  2.917125  0.022862  0.121406   \n",
            "201  people        644  0.007694  0.007665  2.917125  0.022444  0.119291   \n",
            "98    would        555  0.006631  0.006609  2.917125  0.019342  0.103488   \n",
            "503     get        480  0.005735  0.005718  2.917125  0.016729  0.090006   \n",
            "141  really        478  0.005711  0.005694  2.917125  0.016659  0.089645   \n",
            "62      one        473  0.005651  0.005635  2.917125  0.016485  0.088740   \n",
            "\n",
            "     Custom-Metric  \n",
            "93        0.001024  \n",
            "11        0.000422  \n",
            "100       0.000289  \n",
            "61        0.000148  \n",
            "86        0.000061  \n",
            "201       0.000059  \n",
            "98        0.000044  \n",
            "503       0.000033  \n",
            "141       0.000033  \n",
            "62        0.000032  \n",
            "disgust\n",
            "           Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "2          name        876  0.023251  0.022985  3.684845  0.085676  0.320175   \n",
            "103        like        437  0.011599  0.011532  3.684845  0.042740  0.170676   \n",
            "4           not        427  0.011333  0.011270  3.684845  0.041762  0.167032   \n",
            "109  disgusting        366  0.009714  0.009668  3.684845  0.035796  0.144550   \n",
            "93       people        342  0.009077  0.009036  3.684845  0.033449  0.135585   \n",
            "77        weird        309  0.008202  0.008168  3.684845  0.030221  0.123147   \n",
            "118         bad        283  0.007511  0.007483  3.684845  0.027678  0.113254   \n",
            "69        worst        271  0.007193  0.007167  3.684845  0.026505  0.108661   \n",
            "312       worse        253  0.006715  0.006693  3.684845  0.024744  0.101737   \n",
            "377       awful        247  0.006556  0.006535  3.684845  0.024157  0.099420   \n",
            "\n",
            "     Custom-Metric  \n",
            "2         0.000541  \n",
            "103       0.000135  \n",
            "4         0.000128  \n",
            "109       0.000094  \n",
            "93        0.000082  \n",
            "77        0.000067  \n",
            "118       0.000056  \n",
            "69        0.000052  \n",
            "312       0.000045  \n",
            "377       0.000043  \n",
            "embarrassment\n",
            "       Word  Frequency        TF    Log-TF      IDF    TF-IDF      BM25  \\\n",
            "58     name        344  0.019290  0.019106  4.44588  0.085761  0.274771   \n",
            "162     not        208  0.011664  0.011596  4.44588  0.051856  0.173688   \n",
            "4      like        198  0.011103  0.011042  4.44588  0.049363  0.165892   \n",
            "93    shame        156  0.008748  0.008710  4.44588  0.038892  0.132569   \n",
            "43      bad        153  0.008580  0.008543  4.44588  0.038144  0.130152   \n",
            "135   sorry        150  0.008411  0.008376  4.44588  0.037396  0.127730   \n",
            "84    weird        139  0.007795  0.007764  4.44588  0.034654  0.118808   \n",
            "7    people        126  0.007066  0.007041  4.44588  0.031413  0.108178   \n",
            "291   would        123  0.006897  0.006874  4.44588  0.030665  0.105711   \n",
            "44       no        120  0.006729  0.006707  4.44588  0.029917  0.103239   \n",
            "\n",
            "     Custom-Metric  \n",
            "58        0.000372  \n",
            "162       0.000136  \n",
            "4         0.000123  \n",
            "93        0.000077  \n",
            "43        0.000074  \n",
            "135       0.000071  \n",
            "84        0.000061  \n",
            "7         0.000050  \n",
            "291       0.000048  \n",
            "44        0.000045  \n",
            "excitement\n",
            "        Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "18      name        968  0.027206  0.026842  3.624819  0.098615  0.331461   \n",
            "35      like        453  0.012732  0.012651  3.624819  0.046149  0.166888   \n",
            "69     happy        415  0.011664  0.011596  3.624819  0.042278  0.153749   \n",
            "39       wow        375  0.010539  0.010484  3.624819  0.038203  0.139758   \n",
            "104  excited        344  0.009668  0.009622  3.624819  0.035045  0.128800   \n",
            "249      see        293  0.008235  0.008201  3.624819  0.029849  0.110549   \n",
            "30      love        290  0.008150  0.008117  3.624819  0.029544  0.109467   \n",
            "89    really        267  0.007504  0.007476  3.624819  0.027201  0.101136   \n",
            "44       get        256  0.007195  0.007169  3.624819  0.026080  0.097132   \n",
            "122     good        254  0.007139  0.007113  3.624819  0.025876  0.096402   \n",
            "\n",
            "     Custom-Metric  \n",
            "18        0.000740  \n",
            "35        0.000162  \n",
            "69        0.000136  \n",
            "39        0.000111  \n",
            "104       0.000093  \n",
            "249       0.000068  \n",
            "30        0.000066  \n",
            "89        0.000056  \n",
            "44        0.000052  \n",
            "122       0.000051  \n",
            "fear\n",
            "         Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "20       name        497  0.022297  0.022052  4.190403  0.093433  0.303493   \n",
            "83   terrible        256  0.011485  0.011420  4.190403  0.048127  0.166104   \n",
            "115    scared        243  0.010902  0.010843  4.190403  0.045683  0.158203   \n",
            "274    afraid        231  0.010363  0.010310  4.190403  0.043427  0.150862   \n",
            "36       like        220  0.009870  0.009822  4.190403  0.041359  0.144092   \n",
            "35        not        210  0.009421  0.009377  4.190403  0.039479  0.137904   \n",
            "96   horrible        178  0.007986  0.007954  4.190403  0.033463  0.117881   \n",
            "153     would        173  0.007761  0.007731  4.190403  0.032523  0.114721   \n",
            "173     scary        172  0.007716  0.007687  4.190403  0.032335  0.114089   \n",
            "125    people        162  0.007268  0.007242  4.190403  0.030455  0.107741   \n",
            "\n",
            "     Custom-Metric  \n",
            "20        0.000497  \n",
            "83        0.000132  \n",
            "115       0.000119  \n",
            "274       0.000107  \n",
            "36        0.000097  \n",
            "35        0.000089  \n",
            "96        0.000064  \n",
            "153       0.000060  \n",
            "173       0.000060  \n",
            "125       0.000053  \n",
            "gratitude\n",
            "       Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "9    thanks       4701  0.066773  0.064638  2.899685  0.193620  0.661014   \n",
            "20    thank       3964  0.056304  0.054776  2.899685  0.163265  0.581487   \n",
            "91     name       1250  0.017755  0.017599  2.899685  0.051484  0.218097   \n",
            "12     good        928  0.013181  0.013095  2.899685  0.038221  0.165637   \n",
            "181    much        721  0.010241  0.010189  2.899685  0.029696  0.130621   \n",
            "25      not        615  0.008735  0.008697  2.899685  0.025330  0.112280   \n",
            "118    like        477  0.006775  0.006752  2.899685  0.019646  0.087972   \n",
            "21     glad        473  0.006718  0.006696  2.899685  0.019481  0.087260   \n",
            "4      know        455  0.006463  0.006442  2.899685  0.018740  0.084051   \n",
            "105  really        423  0.006008  0.005990  2.899685  0.017422  0.078325   \n",
            "\n",
            "     Custom-Metric  \n",
            "9         0.004459  \n",
            "20        0.003170  \n",
            "91        0.000315  \n",
            "12        0.000174  \n",
            "181       0.000105  \n",
            "25        0.000076  \n",
            "118       0.000046  \n",
            "21        0.000045  \n",
            "4         0.000042  \n",
            "105       0.000036  \n",
            "grief\n",
            "       Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "39     name        117  0.024539  0.024242  5.747454  0.141034  0.334477   \n",
            "100    died         78  0.016359  0.016227  5.747454  0.094023  0.233393   \n",
            "28    sorry         69  0.014471  0.014368  5.747454  0.083174  0.208711   \n",
            "11      not         55  0.011535  0.011469  5.747454  0.066298  0.169231   \n",
            "0      dead         44  0.009228  0.009186  5.747454  0.053039  0.137243   \n",
            "44     like         40  0.008389  0.008354  5.747454  0.048217  0.125392   \n",
            "380  people         39  0.008180  0.008146  5.747454  0.047011  0.122411   \n",
            "96     loss         38  0.007970  0.007938  5.747454  0.045806  0.119422   \n",
            "228     rip         38  0.007970  0.007938  5.747454  0.045806  0.119422   \n",
            "212   death         38  0.007970  0.007938  5.747454  0.045806  0.119422   \n",
            "\n",
            "     Custom-Metric  \n",
            "39        0.000602  \n",
            "100       0.000268  \n",
            "28        0.000209  \n",
            "11        0.000133  \n",
            "0         0.000085  \n",
            "44        0.000070  \n",
            "380       0.000067  \n",
            "96        0.000064  \n",
            "228       0.000064  \n",
            "212       0.000064  \n",
            "joy\n",
            "      Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "0    happy       1185  0.022226  0.021983  3.275489  0.072801  0.291405   \n",
            "1     name       1167  0.021888  0.021652  3.275489  0.071695  0.287488   \n",
            "35    glad        885  0.016599  0.016463  3.275489  0.054370  0.224249   \n",
            "27    like        675  0.012660  0.012581  3.275489  0.041469  0.174757   \n",
            "15    love        607  0.011385  0.011321  3.275489  0.037291  0.158267   \n",
            "91    good        589  0.011047  0.010987  3.275489  0.036185  0.153862   \n",
            "95   enjoy        435  0.008159  0.008126  3.275489  0.026724  0.115492   \n",
            "116    fun        425  0.007971  0.007940  3.275489  0.026110  0.112957   \n",
            "134    one        403  0.007559  0.007530  3.275489  0.024758  0.107361   \n",
            "3      not        389  0.007296  0.007270  3.275489  0.023898  0.103786   \n",
            "\n",
            "     Custom-Metric  \n",
            "0         0.000494  \n",
            "1         0.000479  \n",
            "35        0.000276  \n",
            "27        0.000160  \n",
            "15        0.000130  \n",
            "91        0.000122  \n",
            "95        0.000067  \n",
            "116       0.000064  \n",
            "134       0.000057  \n",
            "3         0.000053  \n",
            "love\n",
            "         Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "1        love       5132  0.095465  0.091179  3.249771  0.310239  0.894248   \n",
            "7        name       2044  0.038022  0.037317  3.249771  0.123564  0.453849   \n",
            "33       like       1351  0.025131  0.024821  3.249771  0.081670  0.319650   \n",
            "146       one        471  0.008761  0.008723  3.249771  0.028473  0.121564   \n",
            "77      would        458  0.008520  0.008484  3.249771  0.027687  0.118368   \n",
            "54     really        386  0.007180  0.007155  3.249771  0.023334  0.100508   \n",
            "177       not        384  0.007143  0.007118  3.249771  0.023214  0.100008   \n",
            "97      loved        359  0.006678  0.006656  3.249771  0.021702  0.093741   \n",
            "394      much        337  0.006269  0.006249  3.249771  0.020372  0.088199   \n",
            "239  favorite        332  0.006176  0.006157  3.249771  0.020070  0.086936   \n",
            "\n",
            "     Custom-Metric  \n",
            "1         0.009114  \n",
            "7         0.001446  \n",
            "33        0.000632  \n",
            "146       0.000077  \n",
            "77        0.000073  \n",
            "54        0.000052  \n",
            "177       0.000051  \n",
            "97        0.000045  \n",
            "394       0.000039  \n",
            "239       0.000038  \n",
            "nervousness\n",
            "        Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "13      name        299  0.022767  0.022512  4.759049  0.108350  0.320043   \n",
            "26      like        148  0.011269  0.011206  4.759049  0.053631  0.169365   \n",
            "25       not        139  0.010584  0.010528  4.759049  0.050370  0.159724   \n",
            "79       get        123  0.009366  0.009322  4.759049  0.044572  0.142386   \n",
            "299  worried        104  0.007919  0.007888  4.759049  0.037687  0.121460   \n",
            "34        no         92  0.007005  0.006981  4.759049  0.033338  0.108051   \n",
            "58     would         89  0.006777  0.006754  4.759049  0.032251  0.104675   \n",
            "78    people         81  0.006168  0.006149  4.759049  0.029352  0.095626   \n",
            "295      one         78  0.005939  0.005922  4.759049  0.028265  0.092215   \n",
            "45    really         78  0.005939  0.005922  4.759049  0.028265  0.092215   \n",
            "\n",
            "     Custom-Metric  \n",
            "13        0.000518  \n",
            "26        0.000127  \n",
            "25        0.000112  \n",
            "79        0.000088  \n",
            "299       0.000063  \n",
            "34        0.000049  \n",
            "58        0.000046  \n",
            "78        0.000038  \n",
            "295       0.000035  \n",
            "45        0.000035  \n",
            "optimism\n",
            "       Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "40     hope       1968  0.029087  0.028672  3.187768  0.092721  0.417914   \n",
            "69     name       1518  0.022436  0.022188  3.187768  0.071520  0.335166   \n",
            "34     good        881  0.013021  0.012937  3.187768  0.041508  0.206116   \n",
            "105   would        733  0.010834  0.010775  3.187768  0.034535  0.173899   \n",
            "27      not        707  0.010449  0.010395  3.187768  0.033310  0.168145   \n",
            "107     get        676  0.009991  0.009942  3.187768  0.031849  0.161248   \n",
            "119    like        652  0.009636  0.009590  3.187768  0.030719  0.155880   \n",
            "85     luck        463  0.006843  0.006820  3.187768  0.021814  0.112732   \n",
            "216  really        437  0.006459  0.006438  3.187768  0.020589  0.106671   \n",
            "194     one        433  0.006400  0.006379  3.187768  0.020401  0.105736   \n",
            "\n",
            "     Custom-Metric  \n",
            "40        0.000846  \n",
            "69        0.000503  \n",
            "34        0.000170  \n",
            "105       0.000117  \n",
            "27        0.000109  \n",
            "107       0.000100  \n",
            "119       0.000093  \n",
            "85        0.000047  \n",
            "216       0.000042  \n",
            "194       0.000041  \n",
            "pride\n",
            "      Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "8     name        184  0.021101  0.020881  5.088259  0.107367  0.278936   \n",
            "84   proud        174  0.019954  0.019758  5.088259  0.101532  0.265385   \n",
            "14    good         91  0.010436  0.010382  5.088259  0.053100  0.146196   \n",
            "51     not         90  0.010321  0.010268  5.088259  0.052516  0.144683   \n",
            "42    like         86  0.009862  0.009814  5.088259  0.050182  0.138609   \n",
            "123   glad         72  0.008257  0.008223  5.088259  0.042013  0.117102   \n",
            "52      no         56  0.006422  0.006401  5.088259  0.032677  0.092037   \n",
            "124   know         55  0.006307  0.006288  5.088259  0.032093  0.090453   \n",
            "240  great         53  0.006078  0.006060  5.088259  0.030926  0.087279   \n",
            "5      one         52  0.005963  0.005946  5.088259  0.030343  0.085688   \n",
            "\n",
            "     Custom-Metric  \n",
            "8         0.000445  \n",
            "84        0.000398  \n",
            "14        0.000109  \n",
            "51        0.000107  \n",
            "42        0.000097  \n",
            "123       0.000068  \n",
            "52        0.000041  \n",
            "124       0.000040  \n",
            "240       0.000037  \n",
            "5         0.000036  \n",
            "realization\n",
            "       Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "45     name       1337  0.020160  0.019959  3.179769  0.064104  0.297892   \n",
            "85      not        976  0.014717  0.014609  3.179769  0.046795  0.224688   \n",
            "70     like        757  0.011414  0.011350  3.179769  0.036295  0.177858   \n",
            "68     know        515  0.007765  0.007735  3.179769  0.024692  0.123816   \n",
            "35       no        481  0.007253  0.007227  3.179769  0.023062  0.116021   \n",
            "14    think        464  0.006996  0.006972  3.179769  0.022247  0.112104   \n",
            "36      one        432  0.006514  0.006493  3.179769  0.020713  0.104697   \n",
            "236  people        426  0.006423  0.006403  3.179769  0.020425  0.103303   \n",
            "51    would        397  0.005986  0.005968  3.179769  0.019035  0.096542   \n",
            "27     time        394  0.005941  0.005923  3.179769  0.018891  0.095840   \n",
            "\n",
            "     Custom-Metric  \n",
            "45        0.000406  \n",
            "85        0.000217  \n",
            "70        0.000130  \n",
            "68        0.000060  \n",
            "35        0.000053  \n",
            "14        0.000049  \n",
            "36        0.000042  \n",
            "236       0.000041  \n",
            "51        0.000036  \n",
            "27        0.000035  \n",
            "relief\n",
            "       Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "0      glad        207  0.022635  0.022383  5.098286  0.115401  0.312217   \n",
            "4      name        172  0.018808  0.018633  5.098286  0.095889  0.265023   \n",
            "38      not        128  0.013997  0.013900  5.098286  0.071359  0.202724   \n",
            "181    good        104  0.011372  0.011308  5.098286  0.057979  0.167256   \n",
            "66    thank         89  0.009732  0.009685  5.098286  0.049617  0.144527   \n",
            "185      no         84  0.009185  0.009143  5.098286  0.046830  0.136852   \n",
            "197    like         84  0.009185  0.009143  5.098286  0.046830  0.136852   \n",
            "23     feel         84  0.009185  0.009143  5.098286  0.046830  0.136852   \n",
            "330    cool         82  0.008967  0.008927  5.098286  0.045715  0.133768   \n",
            "24   better         80  0.008748  0.008710  5.098286  0.044600  0.130676   \n",
            "\n",
            "     Custom-Metric  \n",
            "0         0.000512  \n",
            "4         0.000354  \n",
            "38        0.000196  \n",
            "181       0.000129  \n",
            "66        0.000095  \n",
            "185       0.000084  \n",
            "197       0.000084  \n",
            "23        0.000084  \n",
            "330       0.000080  \n",
            "24        0.000077  \n",
            "remorse\n",
            "      Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "3    sorry       1473  0.084500  0.081119  4.426292  0.374021  0.853616   \n",
            "23    name        312  0.017898  0.017740  4.426292  0.079222  0.247383   \n",
            "113    not        204  0.011703  0.011635  4.426292  0.051799  0.167488   \n",
            "14    like        159  0.009121  0.009080  4.426292  0.040373  0.132500   \n",
            "69      oh        136  0.007802  0.007771  4.426292  0.034533  0.114209   \n",
            "62     bad        115  0.006597  0.006575  4.426292  0.029201  0.097260   \n",
            "27      no        107  0.006138  0.006119  4.426292  0.027169  0.090739   \n",
            "61    feel        105  0.006023  0.006005  4.426292  0.026661  0.089104   \n",
            "154    one        100  0.005737  0.005720  4.426292  0.025392  0.085005   \n",
            "123    get         97  0.005564  0.005549  4.426292  0.024630  0.082539   \n",
            "\n",
            "     Custom-Metric  \n",
            "3         0.007140  \n",
            "23        0.000320  \n",
            "113       0.000137  \n",
            "14        0.000083  \n",
            "69        0.000061  \n",
            "62        0.000044  \n",
            "27        0.000038  \n",
            "61        0.000036  \n",
            "154       0.000033  \n",
            "123       0.000031  \n",
            "sadness\n",
            "       Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "3      name        994  0.021229  0.021007  3.442054  0.073073  0.289050   \n",
            "36    sorry        867  0.018517  0.018348  3.442054  0.063736  0.255899   \n",
            "4       sad        794  0.016958  0.016816  3.442054  0.058370  0.236390   \n",
            "5       not        549  0.011725  0.011657  3.442054  0.040359  0.168361   \n",
            "216    like        446  0.009525  0.009480  3.442054  0.032787  0.138524   \n",
            "47      bad        437  0.009333  0.009290  3.442054  0.032125  0.135881   \n",
            "40     feel        380  0.008116  0.008083  3.442054  0.027935  0.119001   \n",
            "269      no        330  0.007048  0.007023  3.442054  0.024259  0.103994   \n",
            "30   really        321  0.006856  0.006832  3.442054  0.023598  0.101273   \n",
            "120  people        314  0.006706  0.006684  3.442054  0.023083  0.099152   \n",
            "\n",
            "     Custom-Metric  \n",
            "3         0.000451  \n",
            "36        0.000343  \n",
            "4         0.000288  \n",
            "5         0.000137  \n",
            "216       0.000091  \n",
            "47        0.000087  \n",
            "40        0.000066  \n",
            "269       0.000050  \n",
            "30        0.000047  \n",
            "120       0.000045  \n",
            "surprise\n",
            "          Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "18        name       1118  0.031016  0.030545  3.645457  0.113067  0.381746   \n",
            "30         wow        753  0.020890  0.020675  3.645457  0.076154  0.270605   \n",
            "75          oh        540  0.014981  0.014870  3.645457  0.054612  0.200189   \n",
            "192  surprised        452  0.012540  0.012462  3.645457  0.045712  0.169781   \n",
            "7          not        376  0.010431  0.010377  3.645457  0.038026  0.142865   \n",
            "56        like        354  0.009821  0.009773  3.645457  0.035801  0.134957   \n",
            "136     wonder        267  0.007407  0.007380  3.645457  0.027003  0.103159   \n",
            "11         omg        262  0.007268  0.007242  3.645457  0.026497  0.101305   \n",
            "510       know        247  0.006852  0.006829  3.645457  0.024980  0.095727   \n",
            "19      really        239  0.006630  0.006609  3.645457  0.024171  0.092742   \n",
            "\n",
            "     Custom-Metric  \n",
            "18        0.000962  \n",
            "30        0.000436  \n",
            "75        0.000224  \n",
            "192       0.000157  \n",
            "7         0.000109  \n",
            "56        0.000096  \n",
            "136       0.000055  \n",
            "11        0.000053  \n",
            "510       0.000047  \n",
            "19        0.000044  \n",
            "neutral\n",
            "       Word  Frequency        TF    Log-TF       IDF    TF-IDF      BM25  \\\n",
            "4      name      12194  0.033900  0.033338  1.340174  0.045431  0.409719   \n",
            "125     not       5101  0.014181  0.014081  1.340174  0.019005  0.189455   \n",
            "74     like       3958  0.011003  0.010943  1.340174  0.014746  0.149542   \n",
            "60       no       2722  0.007567  0.007539  1.340174  0.010141  0.104801   \n",
            "21      get       2484  0.006906  0.006882  1.340174  0.009255  0.095989   \n",
            "112  people       2345  0.006519  0.006498  1.340174  0.008737  0.090813   \n",
            "16      one       2230  0.006199  0.006180  1.340174  0.008308  0.086514   \n",
            "66    would       2202  0.006122  0.006103  1.340174  0.008204  0.085465   \n",
            "9     think       1939  0.005390  0.005376  1.340174  0.007224  0.075566   \n",
            "87     know       1696  0.004715  0.004704  1.340174  0.006319  0.066347   \n",
            "\n",
            "     Custom-Metric  \n",
            "4         0.001149  \n",
            "125       0.000201  \n",
            "74        0.000121  \n",
            "60        0.000057  \n",
            "21        0.000048  \n",
            "112       0.000042  \n",
            "16        0.000038  \n",
            "66        0.000037  \n",
            "9         0.000029  \n",
            "87        0.000022  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_for_joy = emotion_word_dict['joy']\n",
        "total_words_in_joy = len(words_for_joy)\n",
        "total_texts_in_joy = combined_df[combined_df['joy'] == 1].shape[0]\n",
        "total_texts = combined_df.shape[0]\n",
        "# Compute the statistics\n",
        "word_statistics = calculate_word_statistics(words_for_joy, total_words_in_joy,total_texts_in_joy,total_texts)\n",
        "print(word_statistics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvV0vgaUZwhw",
        "outputId": "15e538f9-f098-40e1-d675-993125af82a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Word  Frequency        TF    Log-TF       IDF    TF-IDF  \\\n",
            "0            happy       1185  0.022226  0.021983  3.275489  0.072801   \n",
            "1             name       1167  0.021888  0.021652  3.275489  0.071695   \n",
            "35            glad        885  0.016599  0.016463  3.275489  0.054370   \n",
            "27            like        675  0.012660  0.012581  3.275489  0.041469   \n",
            "15            love        607  0.011385  0.011321  3.275489  0.037291   \n",
            "...            ...        ...       ...       ...       ...       ...   \n",
            "50         squeals          1  0.000019  0.000019  3.275489  0.000061   \n",
            "4719  unattractive          1  0.000019  0.000019  3.275489  0.000061   \n",
            "4720    appearance          1  0.000019  0.000019  3.275489  0.000061   \n",
            "4722    deservedly          1  0.000019  0.000019  3.275489  0.000061   \n",
            "7711       hostile          1  0.000019  0.000019  3.275489  0.000061   \n",
            "\n",
            "          BM25  Custom-Metric  \n",
            "0     0.291405   4.939939e-04  \n",
            "1     0.287488   4.791005e-04  \n",
            "35    0.224249   2.755316e-04  \n",
            "27    0.174757   1.602848e-04  \n",
            "15    0.158267   1.296171e-04  \n",
            "...        ...            ...  \n",
            "50    0.000278   3.517911e-10  \n",
            "4719  0.000278   3.517911e-10  \n",
            "4720  0.000278   3.517911e-10  \n",
            "4722  0.000278   3.517911e-10  \n",
            "7711  0.000278   3.517911e-10  \n",
            "\n",
            "[7712 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_word_overlap(emotion_word_dict):\n",
        "    \"\"\"\n",
        "    Finds overlapping words between different emotion categories and calculates their occurrences\n",
        "    across the emotions.\n",
        "\n",
        "    :param emotion_word_dict: Dictionary where keys are emotions and values are lists of words.\n",
        "    :return: A DataFrame showing words, the emotions they appear in, and their counts in each emotion.\n",
        "    \"\"\"\n",
        "    from collections import defaultdict\n",
        "\n",
        "    # Create a dictionary to track words across emotions\n",
        "    word_emotion_count = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    # Count occurrences of each word per emotion\n",
        "    for emotion, words in emotion_word_dict.items():\n",
        "        for word in words:\n",
        "            word_emotion_count[word][emotion] += 1\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    rows = []\n",
        "    for word, emotions in word_emotion_count.items():\n",
        "        row = {'Word': word}\n",
        "        row.update(emotions)  # Add counts for each emotion\n",
        "        rows.append(row)\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    df = df.fillna(0).astype({'Word': 'str'})  # Replace NaN with 0\n",
        "    return df.sort_values(by='Word')"
      ],
      "metadata": {
        "id": "3VuwdswIb7eK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overlap_df = find_word_overlap(emotion_word_dict)\n"
      ],
      "metadata": {
        "id": "wThyREY6b8CE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(df, emotion_columns):\n",
        "    \"\"\"\n",
        "    Calculates multiple metrics for a DataFrame with words and their occurrences across specific emotions.\n",
        "\n",
        "    :param df: DataFrame where the first column is \"Word\" and subsequent columns are emotion counts.\n",
        "    :param emotion_columns: List of columns corresponding to specific emotions.\n",
        "    :return: DataFrame with additional metrics.\n",
        "    \"\"\"\n",
        "    # Copy the DataFrame to avoid overwriting the original\n",
        "    df = df.copy()\n",
        "\n",
        "    # Convert emotion columns to numeric, replacing non-numeric values with 0\n",
        "    for col in emotion_columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
        "\n",
        "    # Add EmotionCount (number of emotions with non-zero values for the word)\n",
        "    df['EmotionCount'] = (df[emotion_columns] > 0).sum(axis=1)\n",
        "\n",
        "    # Add EmotionsWithWord (list of emotions where the word appears)\n",
        "    df['EmotionsWithWord'] = df[emotion_columns].apply(\n",
        "        lambda x: ', '.join([col for col in emotion_columns if x[col] > 0]), axis=1\n",
        "    )\n",
        "\n",
        "    # 1. Normalization by emotion (relative weight of each word in the emotion)\n",
        "    for emotion in emotion_columns:\n",
        "        total = df[emotion].sum()\n",
        "        if total > 0:\n",
        "            df[f'Normalized_{emotion}'] = df[emotion] / total\n",
        "        else:\n",
        "            df[f'Normalized_{emotion}'] = 0\n",
        "\n",
        "    # 2. Overlap score (number of emotions the word appears in)\n",
        "    df['Overlap'] = df[emotion_columns].astype(bool).sum(axis=1)\n",
        "\n",
        "    # 3. TF-IDF for each emotion\n",
        "    N = len(emotion_columns)  # Number of emotions\n",
        "    df['DF'] = df[emotion_columns].gt(0).sum(axis=1)  # Document Frequency\n",
        "    for emotion in emotion_columns:\n",
        "        total = df[emotion].sum()\n",
        "        if total > 0:\n",
        "            df[f'TF-IDF_{emotion}'] = (df[emotion] / total) * np.log(N / df['DF'])\n",
        "        else:\n",
        "            df[f'TF-IDF_{emotion}'] = 0\n",
        "\n",
        "    # 4. Unique word indicator (appears in only one emotion)\n",
        "    df['IsUnique'] = (df['Overlap'] == 1).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "    return df\n",
        "overlap_df_stas = calculate_metrics(overlap_df,emotion_columns)\n",
        "# overlap_df_stas = overlap_df_stas.drop(columns=emotion_columns)"
      ],
      "metadata": {
        "id": "x8MpyGj297Wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overlap_df_stas.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "jyB9ZY0I98YZ",
        "outputId": "4a9a8cb6-b3ac-4f17-ef71-a6f69f2c5669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            sadness       neutral          love     gratitude   disapproval  \\\n",
              "count  29671.000000  29671.000000  29671.000000  29671.000000  29671.000000   \n",
              "mean       1.578039     12.123285      1.811803      2.372788      2.821004   \n",
              "std       13.509546    100.725412     34.478431     39.623930     25.877863   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000      1.000000      0.000000      0.000000      0.000000   \n",
              "50%        0.000000      2.000000      0.000000      0.000000      0.000000   \n",
              "75%        0.000000      5.000000      0.000000      0.000000      1.000000   \n",
              "max      994.000000  12194.000000   5132.000000   4701.000000   2679.000000   \n",
              "\n",
              "          amusement  disappointment       disgust    admiration   realization  \\\n",
              "count  29671.000000    29671.000000  29671.000000  29671.000000  29671.000000   \n",
              "mean       2.118803        2.116174      1.269792      3.752654      2.235179   \n",
              "std       25.770088       16.472488     10.034399     36.242097     16.715647   \n",
              "min        0.000000        0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000        0.000000      0.000000      0.000000      0.000000   \n",
              "50%        0.000000        0.000000      0.000000      0.000000      0.000000   \n",
              "75%        1.000000        1.000000      0.000000      2.000000      1.000000   \n",
              "max     3271.000000     1475.000000    876.000000   3202.000000   1337.000000   \n",
              "\n",
              "       ...  TF-IDF_nervousness  TF-IDF_optimism  TF-IDF_pride  \\\n",
              "count  ...        29671.000000     29671.000000  29671.000000   \n",
              "mean   ...            0.000008         0.000008      0.000008   \n",
              "std    ...            0.000033         0.000017      0.000039   \n",
              "min    ...            0.000000         0.000000      0.000000   \n",
              "25%    ...            0.000000         0.000000      0.000000   \n",
              "50%    ...            0.000000         0.000000      0.000000   \n",
              "75%    ...            0.000000         0.000008      0.000000   \n",
              "max    ...            0.001511         0.000288      0.000908   \n",
              "\n",
              "       TF-IDF_realization  TF-IDF_relief  TF-IDF_remorse  TF-IDF_sadness  \\\n",
              "count        29671.000000   29671.000000    29671.000000    29671.000000   \n",
              "mean             0.000009       0.000007        0.000007        0.000008   \n",
              "std              0.000016       0.000040        0.000034        0.000021   \n",
              "min              0.000000       0.000000        0.000000        0.000000   \n",
              "25%              0.000000       0.000000        0.000000        0.000000   \n",
              "50%              0.000000       0.000000        0.000000        0.000000   \n",
              "75%              0.000014       0.000000        0.000000        0.000000   \n",
              "max              0.000329       0.001145        0.000769        0.000559   \n",
              "\n",
              "       TF-IDF_surprise  TF-IDF_neutral      IsUnique  \n",
              "count     29671.000000    29671.000000  29671.000000  \n",
              "mean          0.000009        0.000012      0.073405  \n",
              "std           0.000027        0.000011      0.260805  \n",
              "min           0.000000        0.000000      0.000000  \n",
              "25%           0.000000        0.000003      0.000000  \n",
              "50%           0.000000        0.000010      0.000000  \n",
              "75%           0.000000        0.000017      0.000000  \n",
              "max           0.000810        0.000417      1.000000  \n",
              "\n",
              "[8 rows x 88 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d54e14c1-54e9-4e51-971e-99ba544244b8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sadness</th>\n",
              "      <th>neutral</th>\n",
              "      <th>love</th>\n",
              "      <th>gratitude</th>\n",
              "      <th>disapproval</th>\n",
              "      <th>amusement</th>\n",
              "      <th>disappointment</th>\n",
              "      <th>disgust</th>\n",
              "      <th>admiration</th>\n",
              "      <th>realization</th>\n",
              "      <th>...</th>\n",
              "      <th>TF-IDF_nervousness</th>\n",
              "      <th>TF-IDF_optimism</th>\n",
              "      <th>TF-IDF_pride</th>\n",
              "      <th>TF-IDF_realization</th>\n",
              "      <th>TF-IDF_relief</th>\n",
              "      <th>TF-IDF_remorse</th>\n",
              "      <th>TF-IDF_sadness</th>\n",
              "      <th>TF-IDF_surprise</th>\n",
              "      <th>TF-IDF_neutral</th>\n",
              "      <th>IsUnique</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>29671.000000</td>\n",
              "      <td>29671.000000</td>\n",
              "      <td>29671.000000</td>\n",
              "      <td>29671.000000</td>\n",
              "      <td>29671.000000</td>\n",
              "      <td>29671.000000</td>\n",
              "      <td>29671.000000</td>\n",
              "      <td>29671.000000</td>\n",
              "      <td>29671.000000</td>\n",
              "      <td>29671.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>29671.000000</td>\n",
              "      <td>29671.000000</td>\n",
              "      <td>29671.000000</td>\n",
              "      <td>29671.000000</td>\n",
              "      <td>29671.000000</td>\n",
              "      <td>29671.000000</td>\n",
              "      <td>29671.000000</td>\n",
              "      <td>29671.000000</td>\n",
              "      <td>29671.000000</td>\n",
              "      <td>29671.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.578039</td>\n",
              "      <td>12.123285</td>\n",
              "      <td>1.811803</td>\n",
              "      <td>2.372788</td>\n",
              "      <td>2.821004</td>\n",
              "      <td>2.118803</td>\n",
              "      <td>2.116174</td>\n",
              "      <td>1.269792</td>\n",
              "      <td>3.752654</td>\n",
              "      <td>2.235179</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.073405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>13.509546</td>\n",
              "      <td>100.725412</td>\n",
              "      <td>34.478431</td>\n",
              "      <td>39.623930</td>\n",
              "      <td>25.877863</td>\n",
              "      <td>25.770088</td>\n",
              "      <td>16.472488</td>\n",
              "      <td>10.034399</td>\n",
              "      <td>36.242097</td>\n",
              "      <td>16.715647</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.260805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>994.000000</td>\n",
              "      <td>12194.000000</td>\n",
              "      <td>5132.000000</td>\n",
              "      <td>4701.000000</td>\n",
              "      <td>2679.000000</td>\n",
              "      <td>3271.000000</td>\n",
              "      <td>1475.000000</td>\n",
              "      <td>876.000000</td>\n",
              "      <td>3202.000000</td>\n",
              "      <td>1337.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001511</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>0.000908</td>\n",
              "      <td>0.000329</td>\n",
              "      <td>0.001145</td>\n",
              "      <td>0.000769</td>\n",
              "      <td>0.000559</td>\n",
              "      <td>0.000810</td>\n",
              "      <td>0.000417</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows √ó 88 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d54e14c1-54e9-4e51-971e-99ba544244b8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d54e14c1-54e9-4e51-971e-99ba544244b8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d54e14c1-54e9-4e51-971e-99ba544244b8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-19f1fc4a-615a-402d-a0a6-2e487afc0e4e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-19f1fc4a-615a-402d-a0a6-2e487afc0e4e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-19f1fc4a-615a-402d-a0a6-2e487afc0e4e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#word2vec"
      ],
      "metadata": {
        "id": "6of-JnQDFIKg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VMcbhuFgI5DH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "def train_word2vec_by_emotion(emotion_dict, vector_size=100, window=5, min_count=1, epochs=10):\n",
        "    \"\"\"\n",
        "    Train Word2Vec models for each emotion and a combined model for all words.\n",
        "\n",
        "    :param emotion_dict: Dictionary where keys are emotion labels and values are lists of words for each emotion.\n",
        "    :param vector_size: Size of the embedding vectors.\n",
        "    :param window: Maximum distance between the current and predicted word within a sentence.\n",
        "    :param min_count: Ignores all words with total frequency lower than this.\n",
        "    :param epochs: Number of training iterations for the Word2Vec model.\n",
        "    :return: Dictionary of Word2Vec models for each emotion, including a combined 'AllWords' model.\n",
        "    \"\"\"\n",
        "    emotion_models = {}\n",
        "\n",
        "    # Train Word2Vec model for each emotion\n",
        "    for emotion, words in emotion_dict.items():\n",
        "        sentences = [[word] for word in words]  # Treat each word as its own \"sentence\"\n",
        "        model = Word2Vec(sentences=sentences, vector_size=vector_size, window=window, min_count=min_count, epochs=epochs)\n",
        "        emotion_models[emotion] = model\n",
        "\n",
        "    # Combine all words into a single list for 'AllWords'\n",
        "    all_words = []\n",
        "    for words in emotion_dict.values():\n",
        "        all_words.extend(words)\n",
        "    all_sentences = [[word] for word in all_words]\n",
        "\n",
        "    # Train the combined 'AllWords' model\n",
        "    all_words_model = Word2Vec(sentences=all_sentences, vector_size=vector_size, window=window, min_count=min_count, epochs=epochs)\n",
        "    emotion_models['AllWords'] = all_words_model\n",
        "\n",
        "    return emotion_models\n",
        "\n",
        "def calculate_emotion_distances(emotion_models):\n",
        "    \"\"\"\n",
        "    Calculate pairwise vector distances between emotions based on Word2Vec embeddings.\n",
        "\n",
        "    :param emotion_models: Dictionary of Word2Vec models trained for each emotion.\n",
        "    :return: Dictionary with distances between each pair of emotions.\n",
        "    \"\"\"\n",
        "    emotion_vectors = {}\n",
        "    # Calculate the mean vector for each emotion\n",
        "    for emotion, model in emotion_models.items():\n",
        "        words = list(model.wv.index_to_key)\n",
        "        vectors = [model.wv[word] for word in words]\n",
        "        emotion_vectors[emotion] = sum(vectors) / len(vectors)  # Mean vector for the emotion\n",
        "\n",
        "    # Compute pairwise distances\n",
        "    distances = {}\n",
        "    emotions = list(emotion_vectors.keys())\n",
        "    for i, emotion1 in enumerate(emotions):\n",
        "        for j, emotion2 in enumerate(emotions):\n",
        "            if i < j:  # Avoid duplicate calculations\n",
        "                dist = cosine(emotion_vectors[emotion1], emotion_vectors[emotion2])\n",
        "                distances[(emotion1, emotion2)] = dist\n",
        "    return distances\n",
        "emotion_models = train_word2vec_by_emotion(emotion_word_dict, vector_size=50, epochs=20)\n"
      ],
      "metadata": {
        "id": "sF8OS_tIFJsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist_emotion = calculate_emotion_distances(emotion_models)"
      ],
      "metadata": {
        "id": "dygsThLeGFd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distance_df = pd.DataFrame(\n",
        "    [(emotion1, emotion2, distance) for (emotion1, emotion2), distance in dist_emotion.items()],\n",
        "    columns=[\"Emotion 1\", \"Emotion 2\", \"Distance\"]\n",
        ")\n",
        "distance_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "S2O30nfUGS0m",
        "outputId": "9d13854d-8c14-4928-bb5e-4c069267933d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Emotion 1    Emotion 2  Distance\n",
              "0     sadness      neutral  0.578517\n",
              "1     sadness         love  0.055607\n",
              "2     sadness    gratitude  0.059697\n",
              "3     sadness  disapproval  0.214072\n",
              "4     sadness    amusement  0.030926\n",
              "..        ...          ...       ...\n",
              "401    desire         fear  0.061498\n",
              "402    desire     AllWords  0.670138\n",
              "403    relief         fear  0.242912\n",
              "404    relief     AllWords  0.798786\n",
              "405      fear     AllWords  0.651615\n",
              "\n",
              "[406 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-352f4f1b-f8bb-4d00-9c01-0828e9ed6365\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Emotion 1</th>\n",
              "      <th>Emotion 2</th>\n",
              "      <th>Distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sadness</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.578517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>love</td>\n",
              "      <td>0.055607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>gratitude</td>\n",
              "      <td>0.059697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sadness</td>\n",
              "      <td>disapproval</td>\n",
              "      <td>0.214072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sadness</td>\n",
              "      <td>amusement</td>\n",
              "      <td>0.030926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>desire</td>\n",
              "      <td>fear</td>\n",
              "      <td>0.061498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>desire</td>\n",
              "      <td>AllWords</td>\n",
              "      <td>0.670138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>relief</td>\n",
              "      <td>fear</td>\n",
              "      <td>0.242912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>relief</td>\n",
              "      <td>AllWords</td>\n",
              "      <td>0.798786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>fear</td>\n",
              "      <td>AllWords</td>\n",
              "      <td>0.651615</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>406 rows √ó 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-352f4f1b-f8bb-4d00-9c01-0828e9ed6365')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-352f4f1b-f8bb-4d00-9c01-0828e9ed6365 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-352f4f1b-f8bb-4d00-9c01-0828e9ed6365');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2e175c21-699e-4574-8adc-48cc0edbccd2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e175c21-699e-4574-8adc-48cc0edbccd2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2e175c21-699e-4574-8adc-48cc0edbccd2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_56d3b723-894e-438d-847d-efbee1518074\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('distance_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_56d3b723-894e-438d-847d-efbee1518074 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('distance_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "distance_df",
              "summary": "{\n  \"name\": \"distance_df\",\n  \"rows\": 406,\n  \"fields\": [\n    {\n      \"column\": \"Emotion 1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"realization\",\n          \"desire\",\n          \"admiration\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Emotion 2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"annoyance\",\n          \"relief\",\n          \"realization\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Distance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22550524054034615,\n        \"min\": 0.002837775161604439,\n        \"max\": 0.9443831816369823,\n        \"num_unique_values\": 406,\n        \"samples\": [\n          0.386197771542931,\n          0.07621737507083604,\n          0.4659608272656952\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#attinsh is all wht you need"
      ],
      "metadata": {
        "id": "BtYD9uft6v4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class EmotionVectorModel(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, vocab_size, num_emotions):\n",
        "        super(EmotionVectorModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads, batch_first=True)\n",
        "        self.emotion_embedding = nn.Embedding(num_emotions, embed_dim)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, emotion_id):\n",
        "        # Embedding ◊®◊ê◊©◊ô ◊©◊ú ◊û◊ô◊ú◊ô◊ù\n",
        "        embeddings = self.embedding(input_ids)\n",
        "\n",
        "        # ◊ï◊ß◊ò◊ï◊® ◊®◊í◊©◊ô ◊†◊ï◊°◊£\n",
        "        emotion_vector = self.emotion_embedding(emotion_id).unsqueeze(1)\n",
        "        embeddings = embeddings + emotion_vector\n",
        "\n",
        "        # Mask ◊ú◊ò◊ô◊§◊ï◊ú ◊ë◊û◊ô◊ú◊ô◊ù ◊®◊ô◊ß◊ï◊™ (PAD)\n",
        "        key_padding_mask = ~attention_mask.to(torch.bool)\n",
        "\n",
        "        # Self-Attention\n",
        "        attn_output, _ = self.attention(\n",
        "            embeddings, embeddings, embeddings, key_padding_mask=key_padding_mask\n",
        "        )\n",
        "\n",
        "        return attn_output  # ◊û◊ó◊ñ◊ô◊® ◊ô◊ô◊¶◊ï◊í◊ô◊ù ◊ï◊ß◊ò◊ï◊®◊ô◊ô◊ù ◊ú◊õ◊ú ◊û◊ô◊ú◊î\n"
      ],
      "metadata": {
        "id": "PoS5HaqCa9Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_emotion_dict(dataframe, tokenizer, emotion_columns):\n",
        "\n",
        "    emotion_dict = {emotion: [] for emotion in emotion_columns}\n",
        "\n",
        "    for _, row in dataframe.iterrows():\n",
        "        text = \" \".join(row['preprocessed_text'])\n",
        "\n",
        "        tokenized = tokenizer(\n",
        "            text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=128\n",
        "        )\n",
        "\n",
        "        for emotion in emotion_columns:\n",
        "            if row[emotion] == 1:\n",
        "                emotion_dict[emotion].append({\n",
        "                    'input_ids': tokenized['input_ids'].squeeze(0),\n",
        "                    'attention_mask': tokenized['attention_mask'].squeeze(0),\n",
        "                    'label': torch.tensor(1.0, dtype=torch.float)\n",
        "                })\n",
        "    return emotion_dict\n"
      ],
      "metadata": {
        "id": "-aOCDKQfXRLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "emotion_dict = create_emotion_dict(combined_df, tokenizer, emotion_columns)\n"
      ],
      "metadata": {
        "id": "YzQmCCq8XVnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_emotion_vectors(emotion_dict, model):\n",
        "\n",
        "    emotion_vectors = {}\n",
        "\n",
        "    for emotion, examples in emotion_dict.items():\n",
        "        emotion_vectors[emotion] = []\n",
        "        for example in examples:\n",
        "            input_ids = example['input_ids'].unsqueeze(0)\n",
        "            attention_mask = example['attention_mask'].unsqueeze(0)\n",
        "            emotion_id = torch.tensor([emotion_columns.index(emotion)]).long()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                vectors = model(input_ids, attention_mask, emotion_id)\n",
        "\n",
        "            emotion_vectors[emotion].append(vectors.squeeze(0).numpy())\n",
        "\n",
        "    return emotion_vectors\n"
      ],
      "metadata": {
        "id": "Q8xReQHrYOkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ◊î◊í◊ì◊®◊™ ◊î◊û◊ï◊ì◊ú\n",
        "embed_dim = 128\n",
        "num_heads = 8\n",
        "vocab_size = 10000\n",
        "num_emotions = len(emotion_columns)\n",
        "model = EmotionVectorModel(embed_dim, num_heads, vocab_size, num_emotions)\n",
        "\n",
        "# ◊ô◊¶◊ô◊®◊™ ◊ï◊ï◊ß◊ò◊ï◊®◊ô◊ù\n",
        "emotion_vectors = generate_emotion_vectors(emotion_dict, model)\n",
        "\n",
        "# ◊î◊¶◊í◊™ ◊î◊™◊ï◊¶◊ê◊ï◊™\n",
        "for emotion, vectors in emotion_vectors.items():\n",
        "    print(f\"Emotion: {emotion}, Number of examples: {len(vectors)}\")\n",
        "    print(f\"First example vector shape: {vectors[0].shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "IAuFsVTBYe4p",
        "outputId": "7f77d8ed-65ee-46e7-f742-6471fafcbef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Index' object has no attribute 'index'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-962a9e320376>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# ◊ô◊¶◊ô◊®◊™ ◊ï◊ï◊ß◊ò◊ï◊®◊ô◊ù\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0memotion_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_emotion_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotion_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# ◊î◊¶◊í◊™ ◊î◊™◊ï◊¶◊ê◊ï◊™\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-63-f027b8923e61>\u001b[0m in \u001b[0;36mgenerate_emotion_vectors\u001b[0;34m(emotion_dict, model)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0memotion_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memotion_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Index' object has no attribute 'index'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cosine, euclidean\n",
        "\n",
        "def calculate_word_distances(emotion_vectors, method=\"cosine\"):\n",
        "    \"\"\"\n",
        "    ◊û◊ó◊©◊ë ◊û◊®◊ó◊ß◊ô◊ù ◊ë◊ô◊ü ◊ï◊ï◊ß◊ò◊ï◊®◊ô◊ù ◊©◊ú ◊û◊ô◊ú◊ô◊ù ◊¢◊ë◊ï◊® ◊õ◊ú ◊®◊í◊©.\n",
        "\n",
        "    Args:\n",
        "        emotion_vectors: ◊û◊ô◊ú◊ï◊ü ◊©◊ú ◊®◊í◊©◊ï◊™ ◊¢◊ù ◊ï◊ï◊ß◊ò◊ï◊®◊ô◊ù ◊ú◊õ◊ú ◊û◊ô◊ú◊î.\n",
        "        method: ◊°◊ï◊í ◊î◊û◊ì◊ì ◊ú◊ó◊ô◊©◊ï◊ë ◊î◊û◊®◊ó◊ß ('cosine' ◊ê◊ï 'euclidean').\n",
        "\n",
        "    Returns:\n",
        "        ◊û◊ô◊ú◊ï◊ü ◊©◊ú ◊®◊í◊©◊ï◊™ ◊¢◊ù ◊®◊©◊ô◊û◊ï◊™ ◊û◊®◊ó◊ß◊ô◊ù.\n",
        "    \"\"\"\n",
        "    distances = {}\n",
        "\n",
        "    for emotion, vectors in emotion_vectors.items():\n",
        "        distances[emotion] = []\n",
        "        for vector_set in vectors:\n",
        "            for i in range(len(vector_set)):\n",
        "                for j in range(i + 1, len(vector_set)):\n",
        "                    if method == \"cosine\":\n",
        "                        dist = cosine(vector_set[i], vector_set[j])\n",
        "                    elif method == \"euclidean\":\n",
        "                        dist = euclidean(vector_set[i], vector_set[j])\n",
        "                    distances[emotion].append(dist)\n",
        "    return distances\n",
        "\n",
        "# ◊ó◊ô◊©◊ï◊ë ◊î◊û◊®◊ó◊ß◊ô◊ù\n",
        "distances = calculate_word_distances(emotion_vectors, method=\"cosine\")\n",
        "print(distances)\n"
      ],
      "metadata": {
        "id": "K7OeZOeCYkrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class EmotionVectorModel(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, vocab_size, num_emotions):\n",
        "        super(EmotionVectorModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads, batch_first=True)\n",
        "        self.emotion_embedding = nn.Embedding(num_emotions, embed_dim)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, emotion_id):\n",
        "        embeddings = self.embedding(input_ids)\n",
        "\n",
        "        emotion_vector = self.emotion_embedding(emotion_id).unsqueeze(1)\n",
        "\n",
        "        embeddings = embeddings + emotion_vector\n",
        "\n",
        "        key_padding_mask = ~attention_mask.to(torch.bool)\n",
        "\n",
        "        attn_output, _ = self.attention(\n",
        "            embeddings, embeddings, embeddings, key_padding_mask=key_padding_mask\n",
        "        )\n",
        "\n",
        "        return attn_output\n"
      ],
      "metadata": {
        "id": "jALAUPISTTUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def tokenize_function(text):\n",
        "    return tokenizer(\n",
        "        text,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "RpZvmQLfTZAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_map = {emotion: idx for idx, emotion in enumerate(emotion_columns)}\n"
      ],
      "metadata": {
        "id": "vsVMrEgDTbYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 64\n",
        "num_heads = 4\n",
        "vocab_size = tokenizer.vocab_size\n",
        "num_emotions = len(emotion_columns)\n",
        "\n",
        "model = EmotionVectorModel(embed_dim, num_heads, vocab_size, num_emotions)\n",
        "\n",
        "\n",
        "text = combined_df['preprocessed_text']\n",
        "tokenized = tokenize_function(text)\n",
        "input_ids = tokenized['input_ids']\n",
        "attention_mask = tokenized['attention_mask']\n",
        "emotion_id = torch.tensor([emotion_map['joy']])\n",
        "\n",
        "with torch.no_grad():\n",
        "    vector_output = model(input_ids, attention_mask, emotion_id)\n",
        "\n",
        "print(\"Vector output shape:\", vector_output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "Ttzcx6RRTgII",
        "outputId": "3d164527-d062-4061-b028-8a9eb0d9e314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-77bf413ab377>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-aa9f9e32f55e>\u001b[0m in \u001b[0;36mtokenize_function\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     return tokenizer(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2858\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_target_context_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2859\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_input_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2860\u001b[0;31m             \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_target_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   2918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_valid_text_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2920\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2921\u001b[0m                 \u001b[0;34m\"text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2922\u001b[0m                 \u001b[0;34m\"or `List[List[str]]` (batch of pretokenized examples).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ00vM6pTxzl",
        "outputId": "dbc80acb-4a08-40d1-a07a-cf85207c3354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.6110, -0.0597, -0.0600,  ..., -0.1180, -0.2386,  0.8235],\n",
              "         [-0.6320,  0.1860,  0.5712,  ..., -0.2277, -0.2162,  0.7453],\n",
              "         [-0.7074,  0.0901,  0.2041,  ..., -0.2522, -0.1497,  0.8194],\n",
              "         ...,\n",
              "         [-0.6724,  0.0412,  0.1083,  ..., -0.2751, -0.2504,  0.8317],\n",
              "         [-0.6724,  0.0412,  0.1083,  ..., -0.2751, -0.2504,  0.8317],\n",
              "         [-0.6724,  0.0412,  0.1083,  ..., -0.2751, -0.2504,  0.8317]]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def tokenize_function(text):\n",
        "    return tokenizer(\n",
        "        text,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "combined_df['tokenized'] = combined_df['preprocessed_text'].apply(\n",
        "    lambda x: tokenize_function(\" \".join(x))\n",
        ")\n"
      ],
      "metadata": {
        "id": "oXFFJfiZFTyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_tokenizer_dict = build_emotion_word_dict(combined_df, text_column='tokenized', emotion_columns=emotion_columns)\n"
      ],
      "metadata": {
        "id": "4IlGiwsbKutM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(combined_df, test_size=0.2, random_state=42)\n",
        "val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "tP4-9B7AFWmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GoEmotionsSingleLabelDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, target_emotion, max_length=128):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.target_emotion = target_emotion\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        text = \" \".join(row['preprocessed_text'])\n",
        "\n",
        "        # Convert target emotion to tensor (Binary classification: 1 or 0)\n",
        "        label = torch.tensor(row[self.target_emotion], dtype=torch.float)\n",
        "\n",
        "        encoded = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoded['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoded['attention_mask'].squeeze(0),\n",
        "            'label': label\n",
        "        }\n"
      ],
      "metadata": {
        "id": "Y2Uo2mTlFZn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joy_dataset = GoEmotionsSingleLabelDataset(train_df, tokenizer, target_emotion=\"joy\")\n",
        "sample = joy_dataset[0]\n",
        "\n",
        "for i in range(5):\n",
        "    sample = joy_dataset[i]\n",
        "    print(f\"Sample {i}:\")\n",
        "    print(\"Text IDs:\", sample['input_ids'])\n",
        "    print(\"Label:\", sample['label'])\n",
        "    print(\"Attention Mask:\", sample['attention_mask'])\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "id": "195raipbJSqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEmotionClassifier(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, vocab_size):\n",
        "        super(TransformerEmotionClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads, batch_first=True)\n",
        "        self.fc = nn.Linear(embed_dim, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        embeddings = self.embedding(input_ids)\n",
        "\n",
        "        # Ensure attention_mask is bool and in correct shape\n",
        "        attention_mask = attention_mask.to(torch.bool).T\n",
        "\n",
        "        attn_output, _ = self.attention(\n",
        "            embeddings, embeddings, embeddings, key_padding_mask=~attention_mask\n",
        "        )\n",
        "\n",
        "        pooled_output = attn_output.mean(dim=1)\n",
        "        return self.fc(pooled_output)\n"
      ],
      "metadata": {
        "id": "EN5Eqgw9Er-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 64\n",
        "num_heads = 4\n",
        "vocab_size = 30522\n",
        "\n",
        "\n",
        "emotion_models = {emotion: EmotionAttentionModel(embed_dim, num_heads, vocab_size) for emotion in emotion_columns}\n"
      ],
      "metadata": {
        "id": "GhWhOHexE0y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_emotion_model(model, dataloader, optimizer, criterion, num_epochs=3, device='cpu'):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)  # ◊ï◊ì◊ê ◊©◊ñ◊î ◊†◊õ◊ï◊ü\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Ensure attention_mask is bool\n",
        "            attention_mask = attention_mask.to(torch.bool)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            loss = criterion(logits.view(-1), labels.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(dataloader):.4f}\")\n"
      ],
      "metadata": {
        "id": "SosUhJi1E94Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ◊ô◊¶◊ô◊®◊™ DataLoader ◊¢◊ë◊ï◊® ◊®◊í◊©◊ï◊™\n",
        "batch_size = 16\n",
        "for emotion in emotion_columns:\n",
        "    # DataLoader ◊¢◊ë◊ï◊® ◊î◊®◊í◊©\n",
        "    emotion_dataset = GoEmotionsDataset(train_df, tokenizer, [emotion])\n",
        "    emotion_dataloader = DataLoader(emotion_dataset, batch_size=batch_size, shuffle=True)\n",
        "    print(emotion_dataset)\n",
        "    # ◊î◊í◊ì◊®◊™ ◊î◊û◊ï◊ì◊ú, ◊ß◊®◊ô◊ò◊®◊ô◊ï◊ü, ◊ï◊ê◊ï◊§◊ò◊ô◊û◊ô◊ñ◊¶◊ô◊î\n",
        "    model = emotion_models[emotion]\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # ◊ê◊ô◊û◊ï◊ü\n",
        "    print(f\"Training model for emotion: {emotion}\")\n",
        "    train_emotion_model(model, emotion_dataloader, optimizer, criterion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "8PwtFaZVFDBs",
        "outputId": "cf6a25b3-1974-46d8-a558-ff101148c4e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.GoEmotionsDataset object at 0x7d1121eed0d0>\n",
            "Training model for emotion: admiration\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-2270d76aeb84>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# ◊ê◊ô◊û◊ï◊ü\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training model for emotion: {emotion}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain_emotion_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotion_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-2d4ee47a7c55>\u001b[0m in \u001b[0;36mtrain_emotion_model\u001b[0;34m(model, dataloader, optimizer, criterion, num_epochs, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ◊ï◊ì◊ê ◊©◊ñ◊î ◊†◊õ◊ï◊ü\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-d58dffd903c2>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memotion_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         encoded = self.tokenizer(\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2858\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_target_context_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2859\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_input_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2860\u001b[0;31m             \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_target_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   2968\u001b[0m             )\n\u001b[1;32m   2969\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2970\u001b[0;31m             return self.encode_plus(\n\u001b[0m\u001b[1;32m   2971\u001b[0m                 \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2972\u001b[0m                 \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3044\u001b[0m         )\n\u001b[1;32m   3045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3046\u001b[0;31m         return self._encode_plus(\n\u001b[0m\u001b[1;32m   3047\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3048\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m         return self.prepare_for_model(\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mfirst_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0mpair_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecond_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mprepare_for_model\u001b[0;34m(self, ids, pair_ids, add_special_tokens, padding, truncation, max_length, stride, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[1;32m   3552\u001b[0m             \u001b[0mencoded_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"length\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3554\u001b[0;31m         batch_outputs = BatchEncoding(\n\u001b[0m\u001b[1;32m   3555\u001b[0m             \u001b[0mencoded_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3556\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m                     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m                     \u001b[0;31m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mas_tensor\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtensor_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJAX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_emotion(model, dataloader, device='cuda'):\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            preds = torch.sigmoid(logits).cpu().numpy()\n",
        "            predictions.extend(preds)\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "onWr8gTgFH2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "for emotion in emotion_columns:\n",
        "    model = emotion_models[emotion]\n",
        "    print(f\"Predicting for emotion: {emotion}\")\n",
        "    predictions = predict_emotion(model, test_dataloader)\n",
        "    # ◊ó◊ô◊©◊ï◊ë ◊î◊û◊ò◊®◊ô◊ß◊ï◊™ (F1, Precision, Recall ◊ï◊õ◊ï')\n"
      ],
      "metadata": {
        "id": "r6r7ukoCFIO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Vocabulary"
      ],
      "metadata": {
        "id": "jWIp0yXvV7j5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch\n",
        "\n",
        "class Vocabulary:\n",
        "    def __init__(self, default_indexes=None):\n",
        "        if default_indexes is None:\n",
        "            default_indexes = {}\n",
        "        self.default_indexes = default_indexes\n",
        "        self.init()\n",
        "\n",
        "    def init(self):\n",
        "        self.index_to_word = {**self.default_indexes}\n",
        "        self.word_to_index = {word: idx for idx, word in self.index_to_word.items()}\n",
        "        self.word_counts = Counter()\n",
        "        self.num_words = len(self.default_indexes)\n",
        "        for word in self.index_to_word:\n",
        "            self.word_counts[word] = 1\n",
        "        self.embedding_matrix = None\n",
        "        self.vector_size = 300\n",
        "\n",
        "    def index_words(self, word_list):\n",
        "        for word in word_list:\n",
        "            self.index_word(word)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.word_to_index)\n",
        "\n",
        "    def index_word(self, word, cnt=None):\n",
        "        if word not in self.word_to_index:\n",
        "            idx = len(self.index_to_word)\n",
        "            self.index_to_word[idx] = word\n",
        "            self.word_to_index[word] = idx\n",
        "            self.word_counts[word] = cnt if cnt is not None else 1\n",
        "            self.num_words += 1\n",
        "        else:\n",
        "            self.word_counts[word] += cnt if cnt is not None else 1\n",
        "\n",
        "    def get_words(self, indices):\n",
        "        return [self.index_to_word.get(i, None) for i in indices]\n",
        "\n",
        "    def build_embedding_matrix(self, word2vec_model, embed_dim=300, init='random'):\n",
        "        if init == 'zeros':\n",
        "            self.embedding_matrix = np.zeros((self.num_words, embed_dim))\n",
        "        elif init == 'random':\n",
        "            self.embedding_matrix = np.random.rand(self.num_words, embed_dim)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown initialization method\")\n",
        "\n",
        "        for idx, word in self.index_to_word.items():\n",
        "            if word in word2vec_model:\n",
        "                self.embedding_matrix[idx] = word2vec_model[word]\n",
        "            else:\n",
        "                if init == 'random':\n",
        "                    self.embedding_matrix[idx] = np.random.rand(embed_dim)\n",
        "                else:\n",
        "                    self.embedding_matrix[idx] = np.zeros(embed_dim)\n",
        "\n",
        "        return self.embedding_matrix\n",
        "\n",
        "    def get_word_vector(self, word):\n",
        "        word_idx = self.get_word_index(word)\n",
        "        if word_idx is not None:\n",
        "            return self.embedding_matrix[word_idx]\n",
        "        print(f\"Word '{word}' not found in vocabulary!\")\n",
        "        return None\n",
        "\n",
        "    def get_word_index(self, word):\n",
        "        return self.word_to_index.get(word, None)\n",
        "\n",
        "    def get_word_from_index(self, index):\n",
        "        return self.index_to_word.get(index, None)\n",
        "\n",
        "    def apply_attention(self, sequence, output, temperature=1.0):\n",
        "        attention_weights = torch.softmax(output / temperature, dim=-1)\n",
        "        weighted_sequence = torch.sum(attention_weights.unsqueeze(-1) * sequence, dim=1)\n",
        "        return weighted_sequence\n",
        "\n",
        "    def get_most_similar_words(self, word_vector, top_n=20):\n",
        "        similarities = cosine_similarity([word_vector], self.embedding_matrix)\n",
        "        similar_indices = similarities[0].argsort()[-top_n:][::-1]\n",
        "        similar_words = [(self.index_to_word[idx], similarities[0][idx]) for idx in similar_indices]\n",
        "        return similar_words\n",
        "\n",
        "    def preprocess_goemotions_data(self, dataframe, text_column):\n",
        "        dataframe[text_column] = dataframe[text_column].str.lower()\n",
        "        dataframe[text_column] = dataframe[text_column].str.replace(r'[^a-z\\s]', '', regex=True)\n",
        "        dataframe[text_column] = dataframe[text_column].str.split()\n",
        "        for text in dataframe[text_column]:\n",
        "            self.index_words(text)\n",
        "\n",
        "    def get_combined_features(self, word):\n",
        "        word_vector = self.get_word_vector(word)\n",
        "        if word_vector is None:\n",
        "            word_vector = np.zeros(self.vector_size)\n",
        "        return word_vector\n"
      ],
      "metadata": {
        "id": "X61tJnQeWEhl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}